[{"content":"DOA估计的模糊问题 一些经典的DOA估计算法，例如MUSIC算法，利用了阵列流型矩阵和噪声子空间的正交关系来确定入射信号的角度。因此在使用这些算法时，必须保证流型矩阵中各个导向矢量是线性无关的，这也是为什么要保证阵列天线的个数大于入射信号的个数。\n在讨论阵列的相位模糊时，如果某一个导向矢量可以表示成其他K个导向矢量的线性组合 $$a(\\phi_k,\\theta_k) = \\sum_{i = 1}^K l_ia(\\phi_i,\\theta_i), \\ \\ {l_i} \\ne 0$$ 则称该阵列存在K阶模糊问题，此时会存在测向模糊。当$K=1$时，称一阶模糊或平凡模糊。\n高阶模糊的识别比较复杂，发生的条件也更加有限，一般只讨论一阶模糊的问题，即流型矩阵中的导向矢量存在 $$a({\\phi _i},{\\theta _i}) = a({\\phi _j},{\\theta _j}),\\ \\ i \\ne j$$\n均匀线阵的相位模糊 在讨论均匀线阵的模糊问题时，主要考虑阵元间距带来的相位模糊。\n设$\\theta$为实际的入射信号，如果存在$a(\\hat{\\theta})=a(\\theta)$，此时在运行MUSIC算法时，在$\\theta$和$\\hat{\\theta}$都会出现谱线峰值。\n在均匀线阵中DOA估计的角度范围为$[ - {\\pi \\over 2},{\\pi \\over 2}]$，根据导向矢量的表达式 $$a(\\theta ) = \\begin{bmatrix} e^{j\\omega {\\tau_0}} \u0026amp; e^{j\\omega {\\tau_1}} \u0026amp; \\dots \u0026amp; e^{j\\omega {\\tau_{M-1}}}\\end{bmatrix}$$ 一阶模糊出现的条件为 $$2\\pi \\frac{d}{\\lambda}sin\\hat{\\theta}=2\\pi \\frac{d}{\\lambda}sin\\theta+2k\\pi,\\ \\ k\\in Z$$ 其$d$为相邻两阵元的间距，化简得 $$sin\\hat{\\theta}=sin\\theta+\\frac{k}{d / \\lambda},\\ \\ k \\in Z$$ 根据$sin\\theta$在$[ - {\\pi \\over 2},{\\pi \\over 2}]$上的单调性，我们可以知道一阶模糊是否出现，等价于是否存在除零以外的整数k使得$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$。于是可以推导出均匀线阵出现一阶模糊的条件：\n$d\\le\\frac{1}{2}\\lambda$ 此时$|\\frac{k}{d/\\lambda}|\\ge 2|k|$，为使$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$，k只能取0。 $\\frac{1}{2}\\lambda\u0026lt;d\u0026lt;\\lambda$ 此时$2|k|\u0026gt;|\\frac{k}{d/\\lambda}|\u0026gt; |k|$，取$|k|=1$可得如果入射角满足$|sin\\theta|\u0026lt;\\lambda /d -1$，不会出现多余峰值；否则会出现一个虚假谱峰。 $d\\ge \\lambda$ 此时$|\\frac{k}{d/\\lambda}|\\le |k|$，为使$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$，当$0\\le sin\\theta \\le 1$时，k至少还可以取-1；当$-1\\le sin\\theta \\le 0$时，k至少还可以取1，所以此时一定会出现虚假谱峰。 均匀圆阵的相位模糊 均匀圆阵的相位模糊问题，一般只出现在阵列孔径较大，而阵元数较少的情况下。\n考虑一维均匀圆阵，即只考虑方位角$\\theta$，俯仰角取90度。\n假设出现$a(\\hat{\\theta})=a(\\theta)$，则在第m个阵元上有 $$2\\pi\\frac{r}{\\lambda}cos(\\hat{\\theta}-(m-1)\\frac{2\\pi}{M})=2\\pi\\frac{r}{\\lambda}cos(\\theta-(m-1)\\frac{2\\pi}{M})+2k\\pi$$ 右式减左式可得 $$\\rho_m=\\frac{4\\pi r}{\\lambda}sin(\\frac{\\theta-\\hat{\\theta}}{2})sin(\\frac{\\theta+\\hat{\\theta}}{2}-(m-1)\\frac{2\\pi}{M})=2k\\pi,k\\in Z$$ 同理，在第m+1个阵元上可以得到 $$\\rho_{m+1}=\\frac{4\\pi r}{\\lambda}sin(\\frac{\\theta-\\hat{\\theta}}{2})sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})=2k\u0026rsquo;\\pi,k\\in Z$$ 所以 $$\\frac{\\rho_{m+1}}{\\rho_m}=sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})/sin(\\frac{\\theta+\\hat{\\theta}}{2}-(m-1)\\frac{2\\pi}{M})=\\frac{\\phi_m}{\\phi_{m+1}}=\\frac{k}{k\u0026rsquo;}$$ 即在存在一阶模糊时，上式的结果为有理数。\n根据三角函数的展开定理，可以将$\\phi_{m+1}$用$\\phi_m$表示 $$\\phi_{m+1}=sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})=\\phi_mcos\\frac{2\\pi}{M}-\\sqrt{1-\\phi_m^2}sin\\frac{2\\pi}{M}$$ 于是可以得到均匀圆阵出现一阶模糊的条件（必要条件）：当$M\\ge 5$且为奇数或者$M\\ge 8$且为偶数时，$cos\\frac{2\\pi}{M}$和$\\sin\\frac{2\\pi}{M}$为无理数，此时均匀圆阵不会出现一阶模糊。\n[1] 跃郭, 王宏远, 陬周, Yue G. U. O., Hong-yuan Wang和Zou Zhou. 《阵元间距对MUSIC算法的影响》. 电子学报 35, 期 9 (2007年9月25日): 1675.\n[2] Xiao, Wei, Xian-Ci Xiao和Heng-Ming Tai. 《Rank-1 ambiguity DOA estimation of circular array with fewer sensors》. 收入 The 2002 45th Midwest Symposium on Circuits and Systems, 2002. MWSCAS-2002., 3:III–III, 2002.\n","date":"2023-02-25T15:54:25+08:00","permalink":"https://xland.cyou/p/uca-doa-ambiguity/","title":"DOA估计中均匀圆阵的模糊问题"},{"content":"ChromeOS是Google推出的桌面操作系统，主打基于云应用的轻量操作系统，如今的ChromeOS已经支持Linux模式和直接运行Android应用。由于Google没有开放系统给Chromebook以外的设备，一般电脑安装ChromeOS可以借助开源项目brunch。\nbrunch能够利用ChromeOS的recovery文件，生成可用的系统镜像文件，从而在非Chromebook上安装原生ChromeOS。\n硬件要求 x86_64架构，UEFI启动模式 Intel CPU至少第四代，或者AMD Ryzen 不支持独显，不支持虚拟机，不支持Arm 可以安装Linux子系统（WSL2）的Windows或者Linux系统 空闲空间至少有16G 安装ChromeOS到U盘 下载ChromeOS recovery文件。\n参考自己的CPU型号，选择一个和自己电脑配置接近的chrome设备，在Chromium Dash下载该设备的recovery文件，一般选择最新的发行版本即可。\n我选择的是Lenovo Yoga C630 Chromebook，codename为pantheon，下载发行版本为109的recovery文件。\n如果不知道应该下载哪个recovery，brunch的项目文档里也给了推荐的recovery。\nIntel 1代-9代：选择codename为rammus的设备对应的recovery 10代和11代：选择codename为volteer的设备对应的recovery AMD Ryzen：选择codename为zork的设备对应的recovery 下载brunch的release文件\n在brunch的release页面下载和recovery版本号对应的文件，例如下载的recovery为109，则下载Brunch r109。\n制作ChromeOS镜像文件\n将下载好的Brunch和ChromeOS recovery放在一个文件夹，分别解压。\n打开WSL终端，安装必要软件。\n1 sudo apt update \u0026amp;\u0026amp; sudo apt -y install pv cgpt tar unzip 在终端中运行命令，制作ChromeOS镜像。把chromeos_filename.bin用从recovery中解压得到的文件名替代，脚本运行完成后回到的名为chromeos.img的系统镜像。\n1 sudo bash chromeos-install.sh -src chromeos_filename.bin -dst chromeos.img 命令运行完成后直接键入ENTER结束。\n将镜像文件写入U盘\n下载Rufus，选中要使用的U盘和镜像文件，将镜像写入U盘。\n进入ChromeOS\n重启电脑，进入BIOS设置界面，关闭secure boot，设置优先从USB启动。\n保存并退出BIOS设置，电脑会自动重启并从U盘启动系统，第一次进入系统时需要等待较长时间。\n安装ChromeOS和Windows双系统 获取文件以及解压同“安装ChromeOS到Windows”中的步骤1、2、3。\n安装ChromeOS双系统同样通过在WSL终端中运行脚本完成，首先新建一个文件夹用于安装系统如/mnt/d/brunch，表示在d盘新建文件夹brunch，然后输入命令。\n1 sudo bash chromeos-install.sh -src chromeos_filename.bin -dst /mnt/d/brunch/chromeos.img -s size 把命令中的chromeos_filename.bin用从recovery中解压得到的文件名替代，size用一个数字替代，定义了分配给ChromeOS磁盘空间，不小于14并且为4的倍数（单位GB）。\n等待脚本执行完成后输入dualboot然后键入ENTER。\n下一步可以安装Grub2Win，实现在开机时选择想要进入的系统。本人未作尝试，具体步骤可以参考brunch的官方安装教程。\n安装Grub2Win后，依次点击Manage Boot Menu-Add A New Entry-Type，选择“Create user section”。此时为自动用记事本新建一个文本文件，在之前设置的/mnt/d/brunch文件夹中打开“chromeos.grub.txt”，将该文件中的内容复制到新建的空文本中。保存Grub2Win的更改，重启电脑，选择ChromeOS进入系统。\n","date":"2023-02-05T11:02:40+08:00","permalink":"https://xland.cyou/p/windows-install-chromeos/","title":"Windows下安装ChromeOS"},{"content":"基于Python的Telegram Bot，使用pyTelegramBotAPI库。\n准备 创建Bot 点击START私聊@BotFather，输入/newbot开始创建Bot。\n等到BotFather回复后输入想要创建的Bot名称，BotFather再次回复后输入Bot的username，注意username必须以_bot结尾。\n创建完Bot后就可以获取到Bot的token，Telegram Bot API的调用必须提供token。\n安装pyTelegramBotAPI 使用pip安装pyTelegramBotAPI。\n1 pip install pyTelegramBotAPI Bot的运行原理 Bot和一般的用户一样，都有名称和id，可以通过@username查找到Bot。Bot的运行是通过和所有者服务器上的脚本联合实现的，用户通过Telegram向Bot发送信息，Bot的脚本根据Bot的token，就可以在服务器上通过Telegram提供的Bot API获取到用户发送给Bot的信息，从而实现根据用户发送的信息返回给用户相应的回复。\npyTelegramBotAPI是一个Python库，对Telegram Bot API进行了封装。使得开发者不用对API直接调用，使用pyTelegramBotAPI提供的函数和类就可以实现Telegram Bot API的各种功能。\npyTelegramBotAPI的基础使用 新建bot对象 pyTelegramBotAPI中调用API的methods全部定义在TeleBot类中，通过传入Bot token新建bot对象。\n1 2 3 import telebot bot = telebot.TeleBot(\u0026#34;TOKEN\u0026#34;, parse_mode=None) # You can set parse_mode by default. HTML or MARKDOWN TeleBot类中的函数和Telegram Bot API提供的method同名，但是更改了命名规则，例如API中的getMe在TeleBot类对应于get_me，API中的sendMessage被命名为send_message。\nBot提供给用户的回复是通过handler实现的，对于用户发送给Bot的消息，使用message handler进行处理。\n1 2 3 @bot.message_handler(commands=[\u0026#39;start\u0026#39;, \u0026#39;help\u0026#39;]) def send_welcome(message): bot.reply_to(message, \u0026#34;Howdy, how are you doing?\u0026#34;) 上述代码中表示对于用户发送给Bot的消息，定义一个message_handler，这个message_handler在用户发送了指令/start或/help时执行send_welcome函数，产生对用户的回复”Howdy, how are you doing?“。\nmessage对象 用户对Bot发送消息后，通过Telegram Bot API获得到的是一个名为message的JSON对象，包含了消息内容，用户id等相关信息，详情可参考Telegram官方文档。\n在上述给出的message_handler示例代码中，send_welcome函数传入参数message对象，reply_to通过message中包含的属性chat.id等获取用户id，从而向用户发送回复信息。\n需要注意的是，由于from是Python中的保留字，在pyTelegramBotAPI中，message的属性名from被替换为from_user。\nmessage handler message handler用来对用户发送的message类消息做出反应（用户发送的消息一般都为message，除此之外还有投票poll、频道推文channel post等其他类型），用于处理其他类消息的handler还有poll handler、channel post handler等。\n1 2 3 @bot.message_handler(filters) def function_name(message): bot.reply_to(message, \u0026#34;This is a message handler\u0026#34;) 在message handler的一般形式中，filters用来对message进行筛选，使该message_handler只对特定类型的message进行响应。filters的一般格式为name=argument，name表示筛选类型，argument代表筛选范围。例如commands=['start', 'help']表示只对命令/start和/help做出反应。\n官方给出的filters支持的类型如下：\nname argument Condition content_types list of strings (default [\u0026rsquo;text\u0026rsquo;]) True if message.content_type is in the list of strings. regexp a regular expression as a string True if re.search(regexp_arg) returns True and message.content_type == \u0026rsquo;text\u0026rsquo; (See https://docs.python.org/2/library/re.html) commands list of strings True if message.content_type == \u0026rsquo;text\u0026rsquo; and message.text starts with a command that is in the list of strings. chat_types list of chat types True if message.chat.type in your filter func a function (lambda or function reference) True if the lambda or function reference returns True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import telebot bot = telebot.TeleBot(\u0026#34;TOKEN\u0026#34;) # 只处理命令 \u0026#39;/start\u0026#39; 和 \u0026#39;/help\u0026#39; @bot.message_handler(commands=[\u0026#39;start\u0026#39;, \u0026#39;help\u0026#39;]) def handle_start_help(message): pass # 只处理用户发送内容为“文件”和“音频”的message @bot.message_handler(content_types=[\u0026#39;document\u0026#39;, \u0026#39;audio\u0026#39;]) def handle_docs_audio(message): pass # Handles all text messages that match the regular expression @bot.message_handler(regexp=\u0026#34;SOME_REGEXP\u0026#34;) def handle_message(message): pass # Handles all messages for which the lambda returns True @bot.message_handler(func=lambda message: message.document.mime_type == \u0026#39;text/plain\u0026#39;, content_types=[\u0026#39;document\u0026#39;]) def handle_text_doc(message): pass # Which could also be defined as: def test_message(message): return message.document.mime_type == \u0026#39;text/plain\u0026#39; @bot.message_handler(func=test_message, content_types=[\u0026#39;document\u0026#39;]) def handle_text_doc(message): pass # Handlers can be stacked to create a function which will be called if either message_handler is eligible # This handler will be called if the message starts with \u0026#39;/hello\u0026#39; OR is some emoji @bot.message_handler(commands=[\u0026#39;hello\u0026#39;]) @bot.message_handler(func=lambda msg: msg.text.encode(\u0026#34;utf-8\u0026#34;) == SOME_FANCY_EMOJI) def send_something(message): pass ","date":"2023-01-10T19:39:43+08:00","permalink":"https://xland.cyou/p/telegram-bot/","title":"Telegram Bot（一）Python库pyTelegramBotAPI的使用"},{"content":"神经网络 neural network 神经网络由多个神经元互相连接组成，每个神经元是一个计算单元，位于同一层级的多个神经元组成一个网络层。一般的神经网络一般由三种网络层组成：输入层，隐藏层和输出层。\n神经网络的组成 激活函数 Activatioin Functioin\n神经元的输入经过激活函数得到输出，激活函数的输出值定义了神经元是否被激活。激活函数有几种不同的形式，它的选取取决于期望的神经元输出。\nBinary 输入为正数时神经元输出1，输入为负数时神经元输出0\n$$ f(x)= \\small\\begin{cases} 0, \u0026amp; \\text{if } x \u0026lt; 0 \\newline 1, \u0026amp; \\text{if } x\\geq 0 \\end{cases} $$\nSigmod 由输入值得到0和1之间的连续输出值\n$$ f(x) = {\\large \\frac{1}{1+e^{-x}}} $$\nTanh 由输入值得到-1和1之间的连续输出值\n$$ f(x) = {\\large \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}} $$\nReLU 当输入为负数时输出为0，输入为正数时保持输入值\n$$ f(x)= \\small \\begin{cases} 0, \u0026amp; \\text{if } x \u0026lt; 0\\newline x, \u0026amp; \\text{if } x\\geq 0 \\end{cases} $$\n权重 Weights\n由前一神经元输出到下一神经元输入的加权\n偏置 Bias\n$$ output=activation function(\\sum{(weights * inputs) + bias}) $$\n在PyTorch中建立神经网络 torch.nn提供了建立神经网络需要的组件，在PyTorch中神经网络是一个module，一个神经网络由多个同样是module的网络层组成。所有的神经网络模型都是nn.Module的子类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import os import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms device = \u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39; print(\u0026#39;Using {} device\u0026#39;.format(device)) class NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10), nn.ReLU() ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logits model = NeuralNetwork().to(device) 通过向模型传递输入数据，模型会自动调用forward()，并返回模型输出。\n1 2 3 4 5 X = torch.rand(1, 28, 28, device=device) # 生成模型输入数据 logits = model(X) # 向模型传递输入数据，model.forward()自动执行，得到输出logits pred_probab = nn.Softmax(dim=1)(logits) y_pred = pred_probab.argmax(1) print(f\u0026#34;Predicted class: {y_pred}\u0026#34;) nn.Linear nn.Linear随机初始化每层的权重和偏置，并储存在tensors中\nnn.Flatten nn.Flatten将28x28的图片转换为一个784维的输入向量\nnn.Sequential nn.Sequential是一个module的容器，数据经过nn.Sequential后，会按照定义时的顺序，依次进行运算。\n1 2 3 4 5 6 7 8 9 10 self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU() ) logits = self.linear_relu_stack(x) # x输入linear_relu_stack后，依次经过module nn.Linear(28*28, 512)， # nn.ReLU()，nn.Linear(512, 512)，nn.ReLU() nn.ReLU 激活函数ReLU\n模型参数 神经网络的参数包括每一个网络层的weight和bais，通过模型的parameters()或named_parameters()可以获取模型中的所有参数\n1 2 3 4 print(\u0026#34;Model structure: \u0026#34;, model, \u0026#34;\\n\\n\u0026#34;) for name, param in model.named_parameters(): print(f\u0026#34;Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\u0026#34;) ","date":"2023-01-09T15:14:55+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-model/","title":"PyTorch基础 （三）网络模型"},{"content":"PyTorch provides two data primitives: torch.utils.data.DataLoaderand torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Datasetstores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\nloading a dataset load the Fashion-MNIST dataset from TorchVision. The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 %matplotlib inline import torch from torch.utils.data import Dataset from torchvision import datasets from torchvision.transforms import ToTensor, Lambda import matplotlib.pyplot as plt training_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, # data storage path train=True, # load training data download=True, # download data from internet to root if data don\u0026#39;t found at root transform=ToTensor() # data to tensor ) test_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, train=False, # load test data download=True, transform=ToTensor() ) Iterating and Visualizing the Dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 labels_map = { 0: \u0026#34;T-Shirt\u0026#34;, 1: \u0026#34;Trouser\u0026#34;, 2: \u0026#34;Pullover\u0026#34;, 3: \u0026#34;Dress\u0026#34;, 4: \u0026#34;Coat\u0026#34;, 5: \u0026#34;Sandal\u0026#34;, 6: \u0026#34;Shirt\u0026#34;, 7: \u0026#34;Sneaker\u0026#34;, 8: \u0026#34;Bag\u0026#34;, 9: \u0026#34;Ankle Boot\u0026#34;, } figure = plt.figure(figsize=(8, 8)) cols, rows = 3, 3 for i in range(1, cols * rows + 1): sample_idx = torch.randint(len(training_data), size=(1,)).item() img, label = training_data[sample_idx] figure.add_subplot(rows, cols, i) plt.title(labels_map[label]) plt.axis(\u0026#34;off\u0026#34;) plt.imshow(img.squeeze(), cmap=\u0026#34;gray\u0026#34;) plt.show() Training with DataLoaders While training a model, we use DataLoader to pass samples in \u0026ldquo;minibatches\u0026rdquo;, reshuffle the data at every epoch to reduce model overfitting, and use Python\u0026rsquo;s multiprocessing to speed up data retrieval. To use DataLoader, we need to set the followings paraments:\ndataset-dataset from which to load the data batch_size-how many samples per batch to load shuffle-set to True to have the data reshuffled at every epoch (default: False) 1 2 3 4 from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) We have loaded that dataset into the Dataloader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels(containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled (for finer-grained control over the data loading order.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Display image and label. train_features, train_labels = next(iter(train_dataloader)) # 得到batch_size=64的训练数据 print(f\u0026#34;Feature batch shape: {train_features.size()}\u0026#34;) # output: Feature batch shape: torch.Size([64, 1, 28, 28]) # batch_size为64，训练数据的每一项是一个28x28的图片 print(f\u0026#34;Labels batch shape: {train_labels.size()}\u0026#34;) # 绘制训练数据batch中第一个图像 img = train_features[0].squeeze() label = train_labels[0] plt.imshow(img, cmap=\u0026#34;gray\u0026#34;) plt.show() print(f\u0026#34;Label: {label}\u0026#34;) iter(object[, sentinel]) 用于生成迭代器，传入参数object必须为支持迭代的对象，next() 返回迭代器下一项。\nNormalizatioin Normalization is a common data pre-processing technique that is applied to scale or transform the data to make sure there\u0026rsquo;s an equal learning contribution from each feature.\nTransforms We use transforms to perform some manipulation of the data and make it suitable for training. transform to modify the features and target_transform to modify the labels. ToTensor converts a PIL image or NumPy ndarray into a FloatTensor and scales the image\u0026rsquo;s pixel intensity values in the range [0., 1.]\n","date":"2023-01-07T11:13:45+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-dataset/","title":"PyTorch基础 （二）Dataset和DataLoader"},{"content":"张量（tensor）是一种类似于数组和矩阵的特殊数据结构。tensor类似于NumPy中的ndarray，两者也可以使用相同的内存地址。\n创建Tensor 直接使用数据创建 1 2 3 4 5 import torch import numpy as np data = [[1, 2],[3, 4]] x_data = torch.tensor(data) 使用NumPy array创建 1 2 3 4 5 6 7 8 9 10 np_array = np.array(data) x_np = torch.from_numpy(np_array) print(f\u0026#34;Numpy np_array value: \\n {np_array} \\n\u0026#34;) print(f\u0026#34;Tensor x_np value: \\n {x_np} \\n\u0026#34;) np.multiply(np_array, 2, out=np_array) print(f\u0026#34;Numpy np_array after * 2 operation: \\n {np_array} \\n\u0026#34;) # x_np会和np_array一起改变 print(f\u0026#34;Tensor x_np value after modifying numpy array: \\n {x_np} \\n\u0026#34;) 由于np_array和x_np使用相同的内存地址，两者的值会同时改变\n使用其他tensor创建 tensor可以使用其他tensor的属性（包括tensor的shape，dtype）进行初始化\n1 2 3 4 5 6 7 x_ones = torch.ones_like(x_data) # x_ones会保持和x_data相同的属性，所有元素都为1 print(f\u0026#34;Ones Tensor: \\n {x_ones} \\n\u0026#34;) x_rand = torch.rand_like(x_data, dtype=torch.float) # x_rand保持x_data的属性，dtype设为torch.float print(f\u0026#34;Random Tensor: \\n {x_rand} \\n\u0026#34;) 使用随机数或常数创建 1 2 3 4 5 6 7 8 shape = (2,3,) rand_tensor = torch.rand(shape) ones_tensor = torch.ones(shape) zeros_tensor = torch.zeros(shape) print(f\u0026#34;Random Tensor: \\n {rand_tensor} \\n\u0026#34;) print(f\u0026#34;Ones Tensor: \\n {ones_tensor} \\n\u0026#34;) print(f\u0026#34;Zeros Tensor: \\n {zeros_tensor}\u0026#34;) Tensor的属性 1 2 3 4 5 tensor = torch.rand(3,4) print(f\u0026#34;Shape of tensor: {tensor.shape}\u0026#34;) print(f\u0026#34;Datatype of tensor: {tensor.dtype}\u0026#34;) print(f\u0026#34;Device tensor is stored on: {tensor.device}\u0026#34;) tensor的属性包括维度shape，数据类型dtype，和存储的设备类型device\nTensor的操作 tensor的参考文档 tensor创建时默认处于CPU中，如果要使用GPU进行tensor计算需要使用.to设置\n1 2 3 # 当GPU可用时，将tensor转移到GPU中 if torch.cuda.is_available(): tensor = tensor.to(\u0026#39;cuda\u0026#39;) Tensor索引 1 2 3 4 5 6 tensor = torch.ones(4, 4) print(\u0026#39;First row: \u0026#39;,tensor[0]) print(\u0026#39;First column: \u0026#39;, tensor[:, 0]) # 第一列 print(\u0026#39;Last column:\u0026#39;, tensor[..., -1]) # 最后一列 tensor[:,1] = 0 # 第二列元素置为0 print(tensor) Tensor合并 tensor的合并有两种方法torch.cat和torch.stack\n1 2 t1 = torch.cat([tensor, tensor, tensor], dim=1) t1 = torch.stack([tensor, tensor, tensor], dim=1) Tensor的数学运算 1 2 3 4 5 6 7 8 9 10 11 12 13 # 矩阵乘法 y1 = tensor @ tensor.T y2 = tensor.matmul(tensor.T) y3 = torch.rand_like(tensor) torch.matmul(tensor, tensor.T, out=y3) # 矩阵对应元素相乘 z1 = tensor * tensor z2 = tensor.mul(tensor) z3 = torch.rand_like(tensor) torch.mul(tensor, tensor, out=z3) 单元素的tensor 单元素的tensor可以使用item()转变为Python中的数值量\n1 2 3 agg = tensor.sum() # 将tensor中的元素相加 agg_item = agg.item() # 将单元素agg转为Python数值 print(agg_item, type(agg_item)) 自动赋值运算 自动赋值运算通常在方法后有 _ 作为后缀，在运算中会直接改变运算量\n1 2 3 print(tensor, \u0026#34;\\n\u0026#34;) tensor.add_(5) # add_改变了tensor的元素值，每个元素加上5 print(tensor) Tensor和NumPy Tensor转为NumPy array 1 2 3 4 t = torch.ones(5) print(f\u0026#34;t: {t}\u0026#34;) n = t.numpy() print(f\u0026#34;n: {n}\u0026#34;) tensor和NumPy array共享内存，两者会同时改变\nNumPy array转为Tensor 1 2 n = np.ones(5) t = torch.from_numpy(n) ","date":"2023-01-06T17:12:03+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-tensor/","title":"PyTorch基础 （一）Tensors"},{"content":"之前没有通过引导卸载VMware Workstation，直接把整个文件夹删了，导致卸载不彻底。VMware在安装时会先检测是否已经安装，使得我的电脑无法再次安装VMware Workstation。后来按照官方的卸载教程试了几次都没成功，偶然发现系统环境变量中还有VMware的路径，才解决了这个问题。关键在于卸载后没有删除环境变量，所以被认为没有完全卸载VMware Workstation。\n通过Workstation安装程序自动清理 下载对应版本的安装程序，在当前文件夹打开终端，在终端中输入\n1 VMware-workstation-full-xxx-xxx.exe /clean 停止VMware相关的服务 在Windows搜索框搜索services.msc，打开“服务”，停止所有VMware相关的服务。\nVMware Authorization Service VMware Authentication Service VMware Registration Service VMware DHCP Service VMware NAT Service VMware USB Arbitration Service VMware Workstation Server VMware WSX Service 删除VMware network bridge adapter 打开控制面板\\网络和 Internet\\网络连接 右键，属性，选择VMware Bridge Protocol，卸载 删除VMware相关的网络适配器 打开控制面板\\硬件和声音\\设备管理器 在“查看”工具栏勾选上“显示隐藏的设备” 点击“网络适配器”，卸载名字包含VMware的适配器 删除和VMware有关的文件夹 程序安装目录 数据目录\n默认路径C:\\Program Files(X86)\\VMware\\ 开始菜单中的VMware\n路径C:\\ProgramData\\VMware 快捷方式 其他文件 C:\\Windows\\system32\\vmnat.exe C:\\Windows\\system32\\vmnetbridge.exe C:\\Windows\\system32\\VMNetDHCP.exe C:\\Windows\\system32\\vmnetdhcp.leases C:\\Windows\\system32\\vmxw2ksetup.dll C:\\Windows\\system32\\vnetprobe.exe C:\\Windows\\system32\\vnetprobelib.dll C:\\Windows\\system32\\vnetinst.dll C:\\Windows\\system32\\vnetlib.dll C:\\Windows\\system32\\vnetlib.exe C:\\Windows\\system32\\drivers\\vmnet.sys C:\\Windows\\system32\\drivers\\vmnetx.sys C:\\Windows\\system32\\drivers\\VMparport.sys C:\\Windows\\system32\\drivers\\vmx86.sys C:\\Windows\\system32\\drivers\\vmnetadapter.sys C:\\Windows\\system32\\drivers\\vmnetbridge.sys C:\\Windows\\system32\\drivers\\vmnetuserif.sys C:\\Windows\\system32\\drivers\\hcmon.sys C:\\Windows\\system32\\drivers\\vmusb.sys 注册表\n打开注册表管理器，删除以下注册表 HKEY_CLASSES_ROOT\\Installer\\Features\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\Products\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\UpgradeCodes\\3F935F414A4C79542AD9C8D157A3CC39 HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\{0D94F75A-0EA6-4951-B3AF-B145FA9E05C6} HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\Installer\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\Applications\\vmware.exe 删除环境变量 打开系统环境变量设置，删除VMware Workstation的执行路径\n重启电脑，就完成了VMware Workstation的完全卸载。\n各版本路径存在一些不同，具体参考官方文档。\n","date":"2022-03-19T12:05:03+08:00","permalink":"https://xland.cyou/p/uninstall-vmware/","title":"完全卸载VMware Workstation"},{"content":"关于Hugo Hugo的便利之处在于，用户只需编辑markdown文档，Hugo会自动将markdown文档转换为网页。Hugo根据存放于content文件夹中的用户markdown文件，生成网页源文件，并存放于public文件夹中。\n将博客部署到GitHub Pages，只需将Hugo生成的public文件夹推送到GitHub仓库。\n关于Github Pages 官方文档定义：\nGitHub Pages is a static site hosting service that takes HTML, CSS, and JavaScript files straight from a repository on GitHub, optionally runs the files through a build process, and publishes a website.\nGithub Pages 有两种形式，个人/组织页面和项目页面，两者访问时的url不同，为了能够使用https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/访问个人博客，应当设置成个人页面。\nUser/Organization Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/) Project Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/\u0026lt;PROJECT\u0026gt;/) 创建User Page 在Github新建仓库时，个人页面的创建和项目页面不同：\n用于个人页面的仓库必须被用户（而不是组织）所有，并将仓库命名为\u0026lt;username\u0026gt;.github.io\n个人页面的源文件放置于仓库的默认分支中，项目页面需存放在特定分支\n创建仓库时需要注意，免费用户创建的页面仓库必须设置为Public\n选择 Initialize this repository with a README ，完成仓库创建\n将源文件推送到仓库 在创建的仓库中复制远程仓库地址\n在Hugo生成的文件夹中，在终端中输入\n1 2 3 4 5 6 7 hugo #生成网页源文件 cd public #生成的源文件存放在public文件夹中，只需将该文件夹推送到所创建的仓库中 git init #git初始化 git remote add origin git@github.com:\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git #关联远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; #在本地提交更改 git push -u origin master #将更改推送到远程仓库 此时GitHub仓库中拥有main和master两个分支，其中main分支是创建仓库是自动生成的默认分支，mater分支由本地推送，即博客的网页源文件\nGitHub Pages的个人页面默认从main分支提取网页源文件，所以还需要在仓库的settings-pages-source中将分支改为master分支\n之后即可通过\u0026lt;username\u0026gt;.github.io访问博客页面\n","date":"2022-02-12T19:34:01+08:00","permalink":"https://xland.cyou/p/hugo_blog/","title":"将Hugo博客部署到Github Pages"}]