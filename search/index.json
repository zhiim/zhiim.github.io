[{"content":"PyTorch provides two data primitives: torch.utils.data.DataLoaderand torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Datasetstores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\nloading a dataset load the Fashion-MNIST dataset from TorchVision. The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 %matplotlib inline import torch from torch.utils.data import Dataset from torchvision import datasets from torchvision.transforms import ToTensor, Lambda import matplotlib.pyplot as plt training_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, # data storage path train=True, # load training data download=True, # download data from internet to root if data don\u0026#39;t found at root transform=ToTensor() # data to tensor ) test_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, train=False, # load test data download=True, transform=ToTensor() ) Iterating and Visualizing the Dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 labels_map = { 0: \u0026#34;T-Shirt\u0026#34;, 1: \u0026#34;Trouser\u0026#34;, 2: \u0026#34;Pullover\u0026#34;, 3: \u0026#34;Dress\u0026#34;, 4: \u0026#34;Coat\u0026#34;, 5: \u0026#34;Sandal\u0026#34;, 6: \u0026#34;Shirt\u0026#34;, 7: \u0026#34;Sneaker\u0026#34;, 8: \u0026#34;Bag\u0026#34;, 9: \u0026#34;Ankle Boot\u0026#34;, } figure = plt.figure(figsize=(8, 8)) cols, rows = 3, 3 for i in range(1, cols * rows + 1): sample_idx = torch.randint(len(training_data), size=(1,)).item() img, label = training_data[sample_idx] figure.add_subplot(rows, cols, i) plt.title(labels_map[label]) plt.axis(\u0026#34;off\u0026#34;) plt.imshow(img.squeeze(), cmap=\u0026#34;gray\u0026#34;) plt.show() Training with DataLoaders While training a model, we use DataLoader to pass samples in \u0026ldquo;minibatches\u0026rdquo;, reshuffle the data at every epoch to reduce model overfitting, and use Python\u0026rsquo;s multiprocessing to speed up data retrieval. To use DataLoader, we need to set the followings paraments:\ndataset-dataset from which to load the data batch_size-how many samples per batch to load shuffle-set to True to have the data reshuffled at every epoch (default: False) 1 2 3 4 from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) We have loaded that dataset into the Dataloader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels(containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled (for finer-grained control over the data loading order.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Display image and label. train_features, train_labels = next(iter(train_dataloader)) # 得到batch_size=64的训练数据 print(f\u0026#34;Feature batch shape: {train_features.size()}\u0026#34;) # output: Feature batch shape: torch.Size([64, 1, 28, 28]) # batch_size为64，训练数据的每一项是一个28x28的图片 print(f\u0026#34;Labels batch shape: {train_labels.size()}\u0026#34;) # 绘制训练数据batch中第一个图像 img = train_features[0].squeeze() label = train_labels[0] plt.imshow(img, cmap=\u0026#34;gray\u0026#34;) plt.show() print(f\u0026#34;Label: {label}\u0026#34;) iter(object[, sentinel]) 用于生成迭代器，传入参数object必须为支持迭代的对象，next() 返回迭代器下一项。\nNormalizatioin Normalization is a common data pre-processing technique that is applied to scale or transform the data to make sure there\u0026rsquo;s an equal learning contribution from each feature.\nTransforms We use transforms to perform some manipulation of the data and make it suitable for training. transform to modify the features and target_transform to modify the labels. ToTensor converts a PIL image or NumPy ndarray into a FloatTensor and scales the image\u0026rsquo;s pixel intensity values in the range [0., 1.]\n","date":"2023-01-07T11:13:45+08:00","permalink":"https://xland.cyou/p/pytorch-dataset/","title":"Pytorch基础 Dataset和DataLoader"},{"content":"张量（tensor）是一种类似于数组和矩阵的特殊数据结构。tensor类似于NumPy中的ndarray，两者也可以使用相同的内存地址。 创建Tensor 直接使用数据创建 1 2 3 4 5 import torch import numpy as np data = [[1, 2],[3, 4]] x_data = torch.tensor(data) 使用NumPy array创建 1 2 3 4 5 6 7 8 9 10 np_array = np.array(data) x_np = torch.from_numpy(np_array) print(f\u0026#34;Numpy np_array value: \\n {np_array} \\n\u0026#34;) print(f\u0026#34;Tensor x_np value: \\n {x_np} \\n\u0026#34;) np.multiply(np_array, 2, out=np_array) print(f\u0026#34;Numpy np_array after * 2 operation: \\n {np_array} \\n\u0026#34;) # x_np会和np_array一起改变 print(f\u0026#34;Tensor x_np value after modifying numpy array: \\n {x_np} \\n\u0026#34;) 由于np_array和x_np使用相同的内存地址，两者的值会同时改变\n使用其他tensor创建 tensor可以使用其他tensor的属性（包括tensor的shape，dtype）进行初始化\n1 2 3 4 5 6 7 x_ones = torch.ones_like(x_data) # x_ones会保持和x_data相同的属性，所有元素都为1 print(f\u0026#34;Ones Tensor: \\n {x_ones} \\n\u0026#34;) x_rand = torch.rand_like(x_data, dtype=torch.float) # x_rand保持x_data的属性，dtype设为torch.float print(f\u0026#34;Random Tensor: \\n {x_rand} \\n\u0026#34;) 使用随机数或常数创建 1 2 3 4 5 6 7 8 shape = (2,3,) rand_tensor = torch.rand(shape) ones_tensor = torch.ones(shape) zeros_tensor = torch.zeros(shape) print(f\u0026#34;Random Tensor: \\n {rand_tensor} \\n\u0026#34;) print(f\u0026#34;Ones Tensor: \\n {ones_tensor} \\n\u0026#34;) print(f\u0026#34;Zeros Tensor: \\n {zeros_tensor}\u0026#34;) Tensor的属性 1 2 3 4 5 tensor = torch.rand(3,4) print(f\u0026#34;Shape of tensor: {tensor.shape}\u0026#34;) print(f\u0026#34;Datatype of tensor: {tensor.dtype}\u0026#34;) print(f\u0026#34;Device tensor is stored on: {tensor.device}\u0026#34;) tensor的属性包括维度shape，数据类型dtype，和存储的设备类型device\nTensor的操作 tensor的参考文档 tensor创建时默认处于CPU中，如果要使用GPU进行tensor计算需要使用.to设置\n1 2 3 # 当GPU可用时，将tensor转移到GPU中 if torch.cuda.is_available(): tensor = tensor.to(\u0026#39;cuda\u0026#39;) Tensor索引 1 2 3 4 5 6 tensor = torch.ones(4, 4) print(\u0026#39;First row: \u0026#39;,tensor[0]) print(\u0026#39;First column: \u0026#39;, tensor[:, 0]) # 第一列 print(\u0026#39;Last column:\u0026#39;, tensor[..., -1]) # 最后一列 tensor[:,1] = 0 # 第二列元素置为0 print(tensor) Tensor合并 tensor的合并有两种方法torch.cat和torch.stack\n1 2 t1 = torch.cat([tensor, tensor, tensor], dim=1) t1 = torch.stack([tensor, tensor, tensor], dim=1) Tensor的数学运算 1 2 3 4 5 6 7 8 9 10 11 12 13 # 矩阵乘法 y1 = tensor @ tensor.T y2 = tensor.matmul(tensor.T) y3 = torch.rand_like(tensor) torch.matmul(tensor, tensor.T, out=y3) # 矩阵对应元素相乘 z1 = tensor * tensor z2 = tensor.mul(tensor) z3 = torch.rand_like(tensor) torch.mul(tensor, tensor, out=z3) 单元素的tensor 单元素的tensor可以使用item()转变为Python中的数值量\n1 2 3 agg = tensor.sum() # 将tensor中的元素相加 agg_item = agg.item() # 将单元素agg转为Python数值 print(agg_item, type(agg_item)) 自动赋值运算 自动赋值运算通常在方法后有 _ 作为后缀，在运算中会直接改变运算量\n1 2 3 print(tensor, \u0026#34;\\n\u0026#34;) tensor.add_(5) # add_改变了tensor的元素值，每个元素加上5 print(tensor) Tensor和NumPy Tensor转为NumPy array 1 2 3 4 t = torch.ones(5) print(f\u0026#34;t: {t}\u0026#34;) n = t.numpy() print(f\u0026#34;n: {n}\u0026#34;) tensor和NumPy array共享内存，两者会同时改变\nNumPy array转为Tensor 1 2 n = np.ones(5) t = torch.from_numpy(n) ","date":"2023-01-06T17:12:03+08:00","permalink":"https://xland.cyou/p/pytorch-tensor/","title":"Pytorch基础 Tensors"},{"content":"之前没有通过引导卸载VMware Workstation，直接把整个文件夹删了，导致卸载不彻底。VMware在安装时会先检测是否已经安装，使得我的电脑无法再次安装VMware Workstation。后来按照官方的卸载教程试了几次都没成功，偶然发现系统环境变量中还有VMware的路径，才解决了这个问题。关键在于卸载后没有删除环境变量，所以被认为没有完全卸载VMware Workstation。\n通过Workstation安装程序自动清理 下载对应版本的安装程序，在当前文件夹打开终端，在终端中输入\n1 VMware-workstation-full-xxx-xxx.exe /clean 停止VMware相关的服务 在Windows搜索框搜索services.msc，打开“服务”，停止所有VMware相关的服务。\nVMware Authorization Service VMware Authentication Service VMware Registration Service VMware DHCP Service VMware NAT Service VMware USB Arbitration Service VMware Workstation Server VMware WSX Service 删除VMware network bridge adapter 打开控制面板\\网络和 Internet\\网络连接 右键，属性，选择VMware Bridge Protocol，卸载 删除VMware相关的网络适配器 打开控制面板\\硬件和声音\\设备管理器 在“查看”工具栏勾选上“显示隐藏的设备” 点击“网络适配器”，卸载名字包含VMware的适配器 删除和VMware有关的文件夹 程序安装目录 数据目录\n默认路径C:\\Program Files(X86)\\VMware\\ 开始菜单中的VMware\n路径C:\\ProgramData\\VMware 快捷方式 其他文件 C:\\Windows\\system32\\vmnat.exe C:\\Windows\\system32\\vmnetbridge.exe C:\\Windows\\system32\\VMNetDHCP.exe C:\\Windows\\system32\\vmnetdhcp.leases C:\\Windows\\system32\\vmxw2ksetup.dll C:\\Windows\\system32\\vnetprobe.exe C:\\Windows\\system32\\vnetprobelib.dll C:\\Windows\\system32\\vnetinst.dll C:\\Windows\\system32\\vnetlib.dll C:\\Windows\\system32\\vnetlib.exe C:\\Windows\\system32\\drivers\\vmnet.sys C:\\Windows\\system32\\drivers\\vmnetx.sys C:\\Windows\\system32\\drivers\\VMparport.sys C:\\Windows\\system32\\drivers\\vmx86.sys C:\\Windows\\system32\\drivers\\vmnetadapter.sys C:\\Windows\\system32\\drivers\\vmnetbridge.sys C:\\Windows\\system32\\drivers\\vmnetuserif.sys C:\\Windows\\system32\\drivers\\hcmon.sys C:\\Windows\\system32\\drivers\\vmusb.sys 注册表\n打开注册表管理器，删除以下注册表 HKEY_CLASSES_ROOT\\Installer\\Features\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\Products\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\UpgradeCodes\\3F935F414A4C79542AD9C8D157A3CC39 HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\{0D94F75A-0EA6-4951-B3AF-B145FA9E05C6} HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\Installer\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\Applications\\vmware.exe 删除环境变量 打开系统环境变量设置，删除VMware Workstation的执行路径\n重启电脑，就完成了VMware Workstation的完全卸载。\n各版本路径存在一些不同，具体参考官方文档。\n","date":"2022-03-19T12:05:03+08:00","permalink":"https://xland.cyou/p/uninstall_vmware/","title":"完全卸载VMware Workstation"},{"content":"关于Hugo Hugo的便利之处在于，用户只需编辑markdown文档，Hugo会自动将markdown文档转换为网页。Hugo根据存放于content文件夹中的用户markdown文件，生成网页源文件，并存放于public文件夹中。\n将博客部署到GitHub Pages，只需将Hugo生成的public文件夹推送到GitHub仓库。\n关于Github Pages 官方文档定义：\nGitHub Pages is a static site hosting service that takes HTML, CSS, and JavaScript files straight from a repository on GitHub, optionally runs the files through a build process, and publishes a website.\nGithub Pages 有两种形式，个人/组织页面和项目页面，两者访问时的url不同，为了能够使用https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/访问个人博客，应当设置成个人页面。\nUser/Organization Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/) Project Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/\u0026lt;PROJECT\u0026gt;/) 创建User Page 在Github新建仓库时，个人页面的创建和项目页面不同：\n用于个人页面的仓库必须被用户（而不是组织）所有，并将仓库命名为\u0026lt;username\u0026gt;.github.io\n个人页面的源文件放置于仓库的默认分支中，项目页面需存放在特定分支\n创建仓库时需要注意，免费用户创建的页面仓库必须设置为Public\n选择 Initialize this repository with a README ，完成仓库创建\n将源文件推送到仓库 在创建的仓库中复制远程仓库地址\n在Hugo生成的文件夹中，在终端中输入\n1 2 3 4 5 6 7 hugo #生成网页源文件 cd public #生成的源文件存放在public文件夹中，只需将该文件夹推送到所创建的仓库中 git init #git初始化 git remote add origin git@github.com:\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git #关联远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; #在本地提交更改 git push -u origin master #将更改推送到远程仓库 此时GitHub仓库中拥有main和master两个分支，其中main分支是创建仓库是自动生成的默认分支，mater分支由本地推送，即博客的网页源文件\nGitHub Pages的个人页面默认从main分支提取网页源文件，所以还需要在仓库的settings-pages-source中将分支改为master分支\n之后即可通过\u0026lt;username\u0026gt;.github.io访问博客页面\n","date":"2022-02-12T19:34:01+08:00","permalink":"https://xland.cyou/p/hugo_blog/","title":"将Hugo博客部署到Github Pages"}]