[{"content":"项目地址 classical_doa\n安装 使用 pip 或者从源码安装\n1 2 3 4 5 6 # pip 安装 pip install classical_doa # 从源码安装 git clone https://github.com/zhiim/classical_doa.git cd classical_doa pip install . 使用案例（均匀线阵） 1 import numpy as np Import Signal 和 Array signal.py定义了一些常用的信号类型，信号对应的 Class 都继承自Signal基类, 用于产生多个入射信号\narray.py定义了一些常用的阵列结构，所有的阵列对应的 Class 都继承自Array基类，Array会使用Signal产生的信号以及入射角度，根据阵列接受信号的数学模型生成阵列接受信号的仿真数据\n阵列接收信号的数学模型（窄带信号）: $\\bf{X} = \\bf{A} \\bf{S}$\n其中： $\\bf{X} = \\begin{bmatrix} x_1(t) \u0026amp; x_2(t) \u0026amp; \\dots \u0026amp; x_M(t) \\end{bmatrix}^T$ 是一个$M\\times 1$维的向量，表示阵列接收到的信号\n$\\bf{A} = \\begin{bmatrix} \\bf{a}(\\theta_1) \u0026amp; \\bf{a}(\\theta_2) \u0026amp; \\dots \u0026amp; \\bf{a}(\\theta_N) \\end{bmatrix}$ 是一个$M \\times N$维的矩阵，表示阵列的流型矩阵\n$\\bf{a}(\\theta_n) =\\begin{bmatrix} e^{-j \\omega_0 \\tau_{1n}} \u0026amp; e^{-j \\omega_0 \\tau_{2n}} \\dots \u0026amp; e^{-j \\omega_0 \\tau_{Mn}} \\end{bmatrix}^T$是与入射角度对应的导向矢量\n$\\bf{X} = \\begin{bmatrix} s_1(t) \u0026amp; s_2(t) \u0026amp; \\dots \u0026amp; s_N(t) \\end{bmatrix}^T$ 是一个$N\\times 1$维的向量，表示入射的信号\n1 2 from classical_doa.arrays import UniformLinearArray from classical_doa.signals import ComplexStochasticSignal 设定仿真参数 设定与阵列结构以及信号参数、入射方向有关的仿真参数，产生采样后的阵列接受信号\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 信号参数 num_snapshots = 300 signal_fre = 2e7 fs = 5e7 snr = 0 # 阵列参数 num_antennas = 8 antenna_spacing = 0.5 * (3e8 / signal_fre) # 阵元间距半波长 # 入射角度 angle_incidence = np.array([0, 30, -60]) num_signal = len(angle_incidence) 生成仿真信号 创建Array和Signal的实例，并生成阵列接受信号的仿真数据\n1 2 3 4 5 6 7 8 9 10 # 创建信号实例 signal = ComplexStochasticSignal(nsamples=num_snapshots, fre=signal_fre, fs=fs) # 创建阵列实例 array = UniformLinearArray(m=num_antennas, dd=antenna_spacing) # 使用信号和阵列生成仿真数据 received_data = array.received_signal( signal=signal, snr=snr, angle_incidence=angle_incidence, unit=\u0026#34;deg\u0026#34; ) 估计入射角 algorithm中定义了几种经典的 DOA 估计算法，有些算法会输出空间谱，有些算法会直接输出估计的入射角的值\n首先 import 两个和绘图函数，分别用于展示这两种算法的估计结果\n1 from classical_doa.plot import plot_estimated_value, plot_spatial_spectrum MUSIC 算法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 search_grids = np.arange(-90, 90, 1) from classical_doa.algorithm.music import music music_spectrum = music( received_data=received_data, num_signal=num_signal, array=array, signal_fre=signal_fre, angle_grids=search_grids, unit=\u0026#34;deg\u0026#34;, ) # 绘制空间谱 plot_spatial_spectrum( spectrum=music_spectrum, angle_grids=search_grids, ground_truth=angle_incidence, num_signal=num_signal, ) Root-MUSIC 算法 1 2 3 4 5 6 7 8 9 10 from classical_doa.algorithm.music import root_music rmusic_estimates = root_music( received_data=received_data, num_signal=num_signal, array=array, signal_fre=signal_fre, unit=\u0026#34;deg\u0026#34;, ) plot_estimated_value(estimates=rmusic_estimates, ground_truth=angle_incidence) ESPRIT 算法 1 2 3 4 5 6 7 8 9 10 from classical_doa.algorithm.esprit import esprit esprit_estimates = esprit( received_data=received_data, num_signal=num_signal, array=array, signal_fre=signal_fre, ) plot_estimated_value(estimates=esprit_estimates, ground_truth=angle_incidence) OMP 算法 1 2 3 4 5 6 7 8 9 10 11 12 from classical_doa.algorithm.sparse import omp omp_estimates = omp( received_data=received_data, num_signal=num_signal, array=array, signal_fre=signal_fre, angle_grids=search_grids, unit=\u0026#34;deg\u0026#34;, ) plot_estimated_value(estimates=omp_estimates, ground_truth=angle_incidence) 更多 查看项目主页和仓库，了解更多的功能和使用方法\n","date":"2024-07-07T10:59:51+08:00","permalink":"https://xland.cyou/p/python_package_doa_estimation/","title":"用于 DOA 估计的 Python 包 classical_doa"},{"content":"最近Github向GitHub Student Developer Pack添加了无限使用Github Copilot的权益，大大提升了学生包的价值，学生认证后即可免费体验这款强大的AI编程助手。Github Copilot的实际体验让人不得不感慨AI的强大，Copilot自动补全的代码大多数情况下可以直接使用，大大提升了编程效率；Copilot Chat也可以对各种编程问题提供非常有用的建议。\n除此之外，由于Github Copilot的底层使用了GPT，我们也可以通过Copilot免费使用GPT-4。要实现这样的功能只需要使用开源项目copilot-gpt4-service获取GPT API，然后就可以通过GPT API搭配GPT前端来访问GPT-4，此外还可以使用GPT API部署AI学术助手gpt academic。\ncopilot-gpt4-service：通过Github Copilot Plugin Token调用GPT API。 chatbox：GPT前端，搭配GPT API可以搭建自己的ChatGPT，并和GPT-4对话。 gpt_academic：使用GPT API的AI学术助手，支持英文论文润色，一键翻译论文等功能。 获取GPT API 从Copilot获取GPT API只需要两步\n运行copilot-gpt4-service得到一个API URL用来替代OpenAI的API URL 获取Github Copilot Plugin Token代替OpenAI的API Key 编译可执行文件 copilot-gpt4-service使用Go语言编写，官方未提供编译好的可执行文件，所以只能自己编译，需要下载并安装Go语言编译器，然后将源码下载到本地编译。\n将copilot-gpt4-service克隆到本地\n1 git clone https://github.com/aaamoon/copilot-gpt4-service.git 编译源码，得到一个名为main的可执行文件\n1 2 3 4 # 进入项目目录 cd copilot-gpt4-service # 编译 go build main.go 在终端中执行可执行文件，此时程序会打印出程序运行的端口以及可用的API地址\n1 ./main 选择本地IP对应的API的地址http://127.0.0.1:8080，在浏览器中打开，如果出现下方提示表示程序运行正常\nVery important: please do not make this service public, for personal use only, otherwise the account or Copilot will be banned. 非常重要：请不要将此服务公开，仅供个人使用，否则账户或 Copilot 将被封禁。\n获取Github Copilot Plugin Token 打开新的终端（如果关闭原本终端，正在运行的copilot-gpt4-service也会被关闭），运行Python脚本获取Github Copilot Plugin Token。\n1 2 3 4 # 安装依赖库 pip install -r requests # 运行脚本 python shells/get_copilot_token.py 根据终端输出的提示，在浏览器中打开Github验证页面，输入终端打印的认证码获取Github Copilot Plugin Token。\n使用GPT前端 Chatbox是一款跨平台的GPT前端，可以使用GPT API搭建自己的ChatGPT，下载安装并填入GPT API的URL和Github Copilot Plugin Token即可使用。\n下载并打开chatbox，进行如下设置：\nAI模型提供方选择OpenAI API OpenAI API 密钥填入上一步获取的Github Copilot Plugin Token API 域名填入http://127.0.0.1:8080 模型选择gpt-4或者GPT的其他任意版本 为了验证API返回的结构是否来自GPT-4，可以提问鲁迅为什么暴打周树人，GPT-3.5会胡说八道，GPT-4会给出正确答案。\n搭建GPT Academic 将项目克隆到本地，并进入项目目录\n1 2 git clone https://github.com/binary-husky/gpt_academic.git cd gpt_academic 安装依赖库\n1 pip install -r requirements.txt 修改config.py中的下面几项\n1 2 3 4 5 6 7 API_KEY = \u0026#34;ghu_xxxxx\u0026#34; # Github Copilot Plugin Token API_URL_REDIRECT = {\u0026#34;https://api.openai.com/v1/chat/completions\u0026#34;: \u0026#34;http://127.0.0.1:8080/v1/chat/completions\u0026#34;} CUSTOM_API_KEY_PATTERN = \u0026#34;ghu_[a-zA-Z0-9]{36}\u0026#34; WEB_PORT = 1234 # 固定端口，也可以为其他值 运行程序，程序会自动在浏览器打开GPT Academic的页面，同样可以通过提问验证API配置是否正常\n1 python main.py ","date":"2024-02-12T15:19:19+08:00","permalink":"https://xland.cyou/p/get-access-to-gpt4-with-github-copilot/","title":"通过Github Copilot获取GPT-4 API"},{"content":"环境准备 本文部署的模型是使用TensorFlow2训练的ResNet网络，用于干扰信号识别，原本的模型文件将权重保存在ResNet.h5中。\n从模型文件中读取权重，并使用测试数据进行推理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import ResNet as ResNet import numpy as np # 干扰类型 class_names = [\u0026#39;CSNJ\u0026#39;, \u0026#39;CW\u0026#39;, \u0026#39;LFM\u0026#39;, \u0026#39;MTJ\u0026#39;, \u0026#39;PBNJ\u0026#39;, \u0026#39;PPNJ\u0026#39;] # 权重文件的存储路径 model_path = \u0026#34;ResNet.h5\u0026#34; data_dimension = (256, 256, 1) model = ResNet.ResNet50(data_dimension) # 导入网络模型 model.load_weights(model_path) # 读取测试数据 test_img = np.load(\u0026#39;test_img.npy\u0026#39;) # 转换输入数据的维度 test_img = np.array(test_img) # (256, 256) test_img = np.expand_dims(test_img, axis=2) # (256, 256, 1) test_img = np.expand_dims(test_img, 0) # (1, 256, 256, 1) test_output = model.predict(test_img) # 模型输出的干扰类型 pred = class_names[test_output.argmax()] print(pred) Atlas 200 DK的环境部署采用“开发环境与运行环境分设”的方案，开发环境使用Windows下Linux子系统中的Ubuntu 22.04.3 LTS，CANN版本为6.0.RC1.alpha005。\n参考官方教程开发环境与运行环境分设完成环境配置。\ncann-toolkit 配置 在Ubuntu中安装完Ascend-cann-toolkit后，运行模型转换工具atc时可能会出现报错\n1 error while loading shared libraries: libascend_hal.so: cannot open shared object file: No such file or directory 这是由于无法找到库文件libascend_hal.so，此时可以进入Ascend-cann-toolkit的安装路径，寻找libascend_hal.so\n1 2 3 xu@DESKTOP-9B4N33I:~$ cd Ascend/ascend-toolkit/latest/ xu@DESKTOP-9B4N33I:~/Ascend/ascend-toolkit/latest$ find . -name libascend_hal.so ./x86_64-linux/devlib/libascend_hal.so 将libascend_hal.so复制到任意路径，并将该路径添加到Ascend-cann-toolkit环境变量中的LD_LIBRARY_PATH。\n例如将libascend_hal.so复制到~/Ascend/missing_lib\n1 2 xu@DESKTOP-9B4N33I:~$ mkdir ~/Ascend/missing_lib xu@DESKTOP-9B4N33I:~$ cp ~/Ascend/ascend-toolkit/latestx86_64-linux/devlib/libascend_hal.so ~/Ascend/missing_lib 在~/.bashrc中更改环境变量\n1 export LD_LIBRARY_PATH=${ASCEND_TOOLKIT_HOME}/lib64:${ASCEND_TOOLKIT_HOME}/lib64/plugin/opskernel:${ASCEND_TOOLKIT_HOME}/lib64/plugin/nnengine:/home/xu/Ascend/missing_lib:$LD_LIBRARY_PATH 在终端输入source ~/.bashrc并重启终端，此时atc可以正常运行。\n模型转换 由于TensorFlow2不再支持导出模型为FrozenGraphDef格式，而atc转换TensorFlow模型时只能使用FrozenGraphDef格式，所以本文采用的转换流程是，先将TensorFlow模型导出为SavedModel格式，再将模型转换为ONNX格式，最后使用atc将ONNX模型转换为.om格式。\n将TensorFlow模型导出为SavedModel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import tensorflow as tf import ResNet as ResNet import os model_path = \u0026#39;ResNet.h5\u0026#39; # 权重文件路径 data_dimension = (256, 256, 1) model = ResNet.ResNet50(data_dimension) # 读取网络模型 model.load_weights(model_path) # export model to savedmodel mobilenet_save_path = os.path.join(\u0026#34;./model\u0026#34;) tf.saved_model.save(model, mobilenet_save_path) 将SavedModel转换为ONNX模型 使用tf2onnx将SavedModel转换为.onnx格式的模型。\n1 python -m tf2onnx.convert --saved-model tensorflow-model-path --output model.onnx 由于atc不支持ONNX的高版本算子，转换时tf2onnx的\u0026ndash;opset 参数值需使用默认值15。\n导出的ONNX模型可以使用Netron查看网络结构。使用ONNX模型完成推理以验证模型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import onnxruntime as onnxrt import numpy as np class_names = [\u0026#39;CSNJ\u0026#39;, \u0026#39;CW\u0026#39;, \u0026#39;LFM\u0026#39;, \u0026#39;MTJ\u0026#39;, \u0026#39;PBNJ\u0026#39;, \u0026#39;PPNJ\u0026#39;] # load model model = onnxrt.InferenceSession(\u0026#34;resnet.onnx\u0026#34;, providers=[\u0026#39;AzureExecutionProvider\u0026#39;, \u0026#39;CPUExecutionProvider\u0026#39;]) print(\u0026#34;loading model success!\u0026#34;) # input data test_img = np.load(\u0026#39;test_img.npy\u0026#39;) test_img = np.array(test_img, dtype=np.float32) # (256, 256) test_img = np.expand_dims(test_img, axis=2) # (256, 256, 1) test_img = np.expand_dims(test_img, 0) # (1, 256, 256, 1) # input sf_input = {model.get_inputs()[0].name:test_img} # output output = model.run(None, sf_input) print(\u0026#34;get output of spatial filter success!\u0026#34;) output = np.array(output) pred = class_names[output.argmax()] print(pred) 将ONNX模型转换为om格式 domain_version报错 在Ubuntu终端中运行atc模型转换工具\n1 atc --model=resnet.onnx --framework=5 --output=resnet --soc_version=Ascend310 可能会出现报错\n1 E16005: The model has [2] [--domain_version] fields, but only one is allowed. 这是由于在将模型转换为ONNX是产生了两个(domain, version)（domain_version的概念参考ONNX Concepts）。\n获取ONNX模型中的(domain,version)\n1 2 3 4 import onnx model = onnx.load(\u0026#34;resnet.onnx\u0026#34;) print(model.opset_import) 得到输出\n1 2 3 4 5 [domain: \u0026#34;\u0026#34; version: 15 , domain: \u0026#34;ai.onnx.ml\u0026#34; version: 2 ] 此时只需去除多余的(domain,version)，保留一个即可\n1 2 3 4 5 6 7 8 9 10 11 import onnx model = onnx.load(\u0026#34;resnet.onnx\u0026#34;) # atc 模型转换只支持一个domain_version if len(model.opset_import) \u0026gt; 1: # 删除多余的domain_version model.opset_import.pop() # 将删除domain_version后的模型保存 onnx.save(model, \u0026#34;./resnet.onnx\u0026#34;) 模型输入维度报错 再次运行atc，出现报错\n1 E10001: Value [-1] for parameter [input_2] is invalid. Reason: maybe you should set input_shape to specify its shape. 使用Netron查看网络结构，发现input_2是输入节点，Netron中显示的该节点信息为\n1 2 name: input_2 tensor: float32[unk__618,256,256,1] 输入数据为四维张量，每一个维度分别表示N（数量）H（高）W（宽）C（通道数），例如前面模型推理时使用的数据维度为(1, 256, 256, 1)表示1个高和宽都为256，通道数为1的图像。\n在导出的ONNX模型中维度N的数值为指定，需要在模型转换时使用--input-shape参数指定输入节点的维度\n1 atc --model=resnet.onnx --framework=5 --output=resnet --input-shape=\u0026#34;input_2:1,256,256,1\u0026#34; --soc_version=Ascend310 在Atlas 200 DK中进行模型推理 模型推理时使用的是pyACL接口，并使用了第三库acllite。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import numpy as np import sys import os # 将acllite路径添加到python环境变量 path = os.path.dirname(os.path.abspath(__file__)) sys.path.append(os.path.join(path, \u0026#34;..\u0026#34;)) sys.path.append(os.path.join(path, \u0026#34;../../common\u0026#34;)) sys.path.append(os.path.join(path, \u0026#34;../../common/acllite\u0026#34;)) from acllite_model import AclLiteModel from acllite_resource import AclLiteResource MODEL_PATH = \u0026#34;../model/resnet.om\u0026#34; # init acl_resource = AclLiteResource() acl_resource.init() # load model model = AclLiteModel(model_path=MODEL_PATH) test_img = np.load(\u0026#34;../data/test_img.npy\u0026#34;) test_img = np.array(test_img) # (256, 256) test_img = np.expand_dims(test_img, axis=2) # (256, 256, 1) test_img = np.expand_dims(test_img, 0) # (1, 256, 256, 1) test_img = test_img.astype(np.float32) # get output of model output = model.execute(test_img) output = np.squeeze(output) print(output) class_names = [\u0026#39;CSNJ\u0026#39;, \u0026#39;CW\u0026#39;, \u0026#39;LFM\u0026#39;, \u0026#39;MTJ\u0026#39;, \u0026#39;PBNJ\u0026#39;, \u0026#39;PPNJ\u0026#39;] pred = class_names[output.argmax()] print(pred) ","date":"2023-09-26T12:08:08+08:00","permalink":"https://xland.cyou/p/deploy-deep-learning-model-on-atlas/","title":"在Atlas 200 DK中部署深度学习模型"},{"content":"Btrfs 更据官方文档的说明\nBTRFS is a modern copy on write (COW) filesystem for Linux aimed at implementing advanced features while also focusing on fault tolerance, repair and easy administration.\nBtrfs拥有较多传统文件系统如Ext3/4不具有的高级功能，为我们日常文件系统使用和备份带来了便利。\n写时复制（Copy-on-Write，CoW） Btrfs默认采用CoW机制，将文件指针存放在metadata文件中。在对文件进行更改时，Btrfs会将新的数据写在新的空闲数据块中，数据写入完成后，更新metadata增加将文件指向新的内存块的指针。\n子卷（subvolume） 一个子卷可以看作是Btrfs中的一个文件夹，但是子卷也可以像分区一样被挂载。例如在subvolume-test中创建一个子卷subvolume，就相当于创建了一个对应的文件夹。\n1 2 3 4 5 6 7 8 ❯ mkdir subvolume-test \u0026amp;\u0026amp; cd subvolume-test ❯ sudo btrfs subvolume create subvolume # 创建子卷 Create subvolume \u0026#39;./subvolume\u0026#39; ❯ ls -l 总计 0 drwxr-xr-x 1 root root 0 7月10日 17:19 subvolume # 当前目录出现对应的文件夹 ❯ sudo btrfs subvolume list -o . # 查看当前目录下存在的子卷 ID 263 gen 6134 top level 257 path @home/xu/subvolume-test/subvolume 如果把子卷挂载到某一目录中，那么该目录内的内容就和该子卷相同了。\n1 2 3 4 5 6 7 8 9 10 ❯ mkdir mount-test # 创建挂载文件夹 ❯ sudo mount -o subvol=@home/xu/subvolume-test/subvolume /dev/nvme0n1p6 mount-test ❯ sudo touch subvolume/test # 在子卷内新建文件 ❯ tree . . ├── mount-test │ └── test # 挂载文件夹内容和子卷相同 └── subvolume └── test 3 directories, 2 files Btrfs文件系统中默认会存在一个ID为5的根子卷，用户创建的子卷都是根子卷下的嵌套子卷。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ❯ mkdir rootsub ❯ sudo mount -o subvolid=5 /dev/nvme0n1p6 rootsub # 挂载根子卷 ❯ ls rootsub @ @home # 根子卷下包含的子卷 ❯ df 文件系统 1K的块 已用 可用 已用% 挂载点 dev 3929540 0 3929540 0% /dev run 3941308 1480 3939828 1% /run /dev/nvme0n1p6 251133952 38761288 210874440 16% / tmpfs 3941308 157696 3783612 5% /dev/shm /dev/nvme0n1p6 251133952 38761288 210874440 16% /home tmpfs 3941312 19428 3921884 1% /tmp /dev/nvme0n1p8 523248 6172 517076 2% /efi tmpfs 788260 76 788184 1% /run/user/1000 onedriver 1131413504 200908800 930504704 18% /home/xu/OneDrive /dev/nvme0n1p6 251133952 38761288 210874440 16% /home/xu/rootsub 可以看到我的根子卷下创建了@子卷和@home子卷分别挂载在/和/home文件夹下。每一个子卷都可以达到文件系统的总容量，使用子卷挂载/和/home就免除了某一个分区空间不足的烦恼。\n快照（snapshot） 快照可以看作是一个子卷，对一个子卷创建快照就是创建了一个新的子卷，这个新的子卷内容和原本子卷完全相同，但是快照不会包含子卷内的嵌套子卷。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ❯ mkdir snapshot-test \u0026amp;\u0026amp; cd snapshot-test ❯ sudo btrfs subvolume create demo # 创建子卷demo Create subvolume \u0026#39;./demo\u0026#39; ❯ sudo touch demo/a demo/b ❯ sudo btrfs subvolume snapshot demo demo-snapshot # 创建子卷的快照 Create a snapshot of \u0026#39;demo\u0026#39; in \u0026#39;./demo-snapshot\u0026#39; ❯ tree . ├── demo │ ├── a │ └── b └── demo-snapshot # 快照和子卷具有相同的内容 ├── a └── b 3 directories, 4 files 得益于CoW的特性，Btrfs创建快照时并不会将原子卷中的内容复制到快照子卷中，而是在快照中创建了指向原子卷内容的指针。如果对子卷内的文件进行更改，原本内容在数据块中不会改变，只是增加了指向新数据块的指针。\n使用快照备份系统 得益于Btrfs的快照特性，我们可以快速方便地备份和回滚系统，而且系统快照只会占用很小的储存空间，在备份方案上，我选择使用Snapper创建和管理系统快照。\nSnapper自动备份 首先安装Snapper\n1 sudo pacman -S snapper 为挂载在/目录下的子卷创建命名为root的快照配置文件\n1 sudo snapper -c root create-config / 此时Snapper会在/etc/snapper/configs生成配置文件，并且在根目录/挂载的子卷即@下创建.snapshots子卷，所有快照都会存储在.snapshots子卷下\n1 2 3 4 5 6 ❯ sudo btrfs subvolume list / ID 256 gen 6803 top level 5 path @ ID 257 gen 6803 top level 5 path @home ID 258 gen 17 top level 256 path var/lib/portables ID 259 gen 18 top level 256 path var/lib/machines ID 266 gen 6800 top level 256 path .snapshots # 挂载在@子卷下 Snapper可以自动创建和清除快照，默认会每小时创建一个快照，每天清理一次快照，在清理时会保存10个每小时快照、10个每日快照、10个每月快照、10个每年快照，但是对于日常使用更改较频繁的子卷我们不需要这么频繁的快照。\n修改/lib/systemd/system/snapper-timeline.timer，设置每6小时创建一次快照\n1 2 3 4 5 6 7 8 9 [Unit] Description=Timeline of Snapper Snapshots Documentation=man:snapper(8) man:snapper-configs(5) [Timer] OnCalendar=00/3:00 # 每3小时创建一次快照 [Install] WantedBy=timers.target 修改配置文件/etc/snapper/configs/root中的变量，改变清理是保留的快照数量\n1 2 3 4 5 6 TIMELINE_MIN_AGE=\u0026#34;1800\u0026#34; TIMELINE_LIMIT_HOURLY=\u0026#34;3\u0026#34; # 保留3个小时快照 TIMELINE_LIMIT_DAILY=\u0026#34;7\u0026#34; # 保留7个每日快照 TIMELINE_LIMIT_WEEKLY=\u0026#34;0\u0026#34; TIMELINE_LIMIT_MONTHLY=\u0026#34;0\u0026#34; TIMELINE_LIMIT_YEARLY=\u0026#34;0\u0026#34; 开启Snapper自动快照和自动清理\n1 2 sudo systemctl enable --now snapper-timeline.timer sudo systemctl enable --now snapper-cleanup.timer 改变快照存储位置 Snapper默认把快照存储在@子卷内的.snapshots分卷下，如果@子卷损坏.snapshots也可能受影响，所以更好的子卷结构是把快照存储在@snapshots子卷下，然后把@snapshots挂载在根子卷下，这样@和@snapshots互不影响。\n删除默认的.snapshots子卷\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ❯ sudo btrfs subvolume list / ID 256 gen 7144 top level 5 path @ ID 257 gen 7144 top level 5 path @home ID 258 gen 17 top level 256 path var/lib/portables ID 259 gen 18 top level 256 path var/lib/machines ID 266 gen 7115 top level 256 path .snapshots ID 267 gen 6963 top level 266 path .snapshots/1/snapshot ID 272 gen 6995 top level 266 path .snapshots/2/snapshot # 如果已经有快照，需要先删除.snapshots里面的快照子卷 ❯ sudo btrfs subvolume delete .snapshots/1/snapshot Delete subvolume (no-commit): \u0026#39;/.snapshots/1/snapshot\u0026#39; ❯ sudo btrfs subvolume delete .snapshots/2/snapshot Delete subvolume (no-commit): \u0026#39;/.snapshots/2/snapshot\u0026#39; ❯ sudo btrfs subvolume delete .snapshots Delete subvolume (no-commit): \u0026#39;//.snapshots\u0026#39; 在根子卷下并列@子卷创建一个@snapshots子卷\n1 2 sudo mount -o subvolid=5 /dev/nvme0n1p6 ~/rootsub # 挂载根子卷 sudo btrfs subvolume create ~/rootsub/@snapshots # 在根子卷下创建子卷 编辑/etc/fstab，将@subvolume子卷挂载到./snapshots\n1 2 # 仿照@和@home子卷的挂载更改 UUID=d26ed334-68d4-481d-894f-838783fa4f88 /.snapshots btrfs rw,relatime,compress=zstd:3,ssd,discard=async,space_cache=v2,subvolid=275,subvol=/@snapshots 0 0 挂载@snapshots子卷\n1 2 3 sudo mkdir /.snapshots sudo mount -a sudo chmod 750 /.snapshots # 阻止非root用户访问 Btrfs的快照不会备份其他子卷的内容，所以我们也可以把/var/cache/pacman/pkg、/var/abs、/var/tmp和/srv等经常读写但有没必要备份的文件夹挂载成子卷。\n从快照中恢复 假设我们已经为/创建了快照，如果想要从快照中恢复系统，可以先进入Arch Linux live USB，然后挂载Btrfs分区\n1 2 sudo mount /dev/nvme0n1p6 /mnt cd /mnt 移除旧的@子卷\n1 sudo mv /mnt/@ /mnt/@.broken 列出所有快照和对应的时间信息\n1 2 3 $ sudo grep -r \u0026#39;\u0026lt;date\u0026gt;\u0026#39; /mnt/@snapshots/*/info.xml /.snapshots/1/info.xml: \u0026lt;date\u0026gt;2023-07-11 06:21:53\u0026lt;/date\u0026gt; # Snapper使用UTC时间记录快照创建时间 /.snapshots/2/info.xml: \u0026lt;date\u0026gt;2022-07-11 06:22:39\u0026lt;/date\u0026gt; 由于Snapper创建的快照是只读子卷，所以需要从快照中创建可读写快照作为@子卷\n1 sudo btrfs subvolume snapshot /mnt/@snapshots/{number}/snapshot /mnt/@ 然后就可以删除旧的@子卷\n1 sudo btrfs subvolume delete /mnt/@.broken Reference ArchWiki-Btrfs Working with Btrfs – General Concepts Working with Btrfs – Subvolumes Working with Btrfs – Snapshots ArchWiki-Snapper BTRFS snapshots and system rollbacks on Arch Linux ","date":"2023-07-11T14:54:53+08:00","image":"https://xland.cyou/p/arch-linux-configuration-driver-and-software/arch.webp","permalink":"https://xland.cyou/p/arch-linux-configuration-btrfs-and-system-backup/","title":"Arch Linux 配置 — Btrfs与系统备份"},{"content":"由于滚动更新的机制，Arch Linux采用的linux内核更新较频繁，难免会碰到由于内核更新无法进入系统。为了解决由于内核更新导致的系统故障，我们可以同时安装更新周期更长的linux-lts内核，如果linux内核更新后无法进入系统，此时就可以选择加载linux-lts内核进入系统，回退linux内核或者等待修复。\n安装linux-lts内核 首先安装linux-lts内核\n1 sudo pacman linux-lts linux-lts-headers 此时重启如果使用GRUB引导系统的话，会出现“Advanced Options for Arch Linxu”，选择这一项就会进入选择启动linux内核或者linux-lts内核的自选单。\n如果使用rEFInd引导系统的话，此时选择进入Arch Linux会默认加载最后安装的内核即linux-lts，选中Arch Linux图标在按F2键的话就会进入选择加载不同内核的选单。\n为了更加方便地在Boot Loader界面选择想要加载的内核，我们可以分别对GRUB和rEFInd进行一些配置。\n配置GRUB 我们想要的是在进入GRUB界面后，直接列出了加载不同内核的选项，而不需要先进入子选单再选择内核。编辑/etc/default/grub，取消注释\n1 GRUB_DISABLE_SUBMENU=y 如果使用的文件系统不是btrfs，还可以配置GRUB自动选中上一次选择加载的选项，这样可以免除每次重新选择。同样编辑/etc/default/grub，对下面几项进行更改\n1 2 GRUB_DEFAULT=saved GRUB_SAVEDEFAULT=true 配置rEFInd rEFInd每次会默认加载最后安装的内核，所以如果不按F2进入子选单选择linux内核就会自动加载linux-lts内核。\n通过更改rEFInd配置文件，我们可以实现默认加载进入linux内核，然后通过子选单选择加载linux-lts内核。同时我们也可以选择附加内核参数，使得每次加载内核的同时加载微码，防止出现一些意外奔溃。\n为了让rEFInd支持Btrfs子卷，需要为rEFInd安装驱动\n1 2 # 我的ESP分区挂载在/efi下 sudo cp /usr/share/refind/drivers_x64/btrfs_x64.efi /efi/EFI/refind/drivers_x64/btrfs_x64.efi 编辑rEFInd配置文件/efi/EFI/refind/refind.conf，我的ESP分区挂载在/efi，如果ESP分区挂载在/boot下的话配置文件路径为/boot/efi/EFI/refind/refind.conf。\n让rEFInd能够匹配Arch Linux的不同内核\n1 extra_kernel_version_strings linux-hardened,linux-zen,linux-lts,linux 让rEFInd能够在Btrfs子卷下自动扫描内核\n1 also_scan_dirs boot,ESP2:EFI/linux/kernels,@/boot 为了实现rEFInd默认加载linux内核，修改配置文件/efi/EFI/refind/refind.conf，手动添加启动项\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 我使用的是Btrfs文件系统，请更加自己的文件系统和内核位置更改路径选项 menuentry \u0026#34;Arch Linux\u0026#34; { icon /EFI/refind/themes/refind-theme-regular/icons/128-48/os_arch.png volume \u0026#34;arch\u0026#34; # Arch 文件系统所在卷对应的标签（Label） loader /@/boot/vmlinuz-linux # 默认加载linux内核 initrd /@/boot/initramfs-linux.img # linux内核对应的initramfs # options选项需要更据GRUB配置文件中的内核参数更改 # options的最后一项设定加载Intel微码，需要确定微码的路径 options \u0026#34;root=UUID=d26ed334-68d4-481d-894f-838783fa4f88 rw rootflags=subvol=@ loglevel=5 nowatchdog initrd=@\\boot\\intel-ucode.img\u0026#34; # 子选单定义，用于加载备用initramfs和linux-lts内核 submenuentry \u0026#34;Boot using fallback initramfs\u0026#34; { initrd /@/boot/initramfs-linux-fallback.img # linux内核的备用initramfs } submenuentry \u0026#34;Boot to linux-lts\u0026#34; { loader /@/boot/vmlinuz-linux-lts # 加载linux-lts内核 initrd /@/boot/initramfs-linux-lts.img # linux-lts内核对应的initramfs } submenuentry \u0026#34;Boot to linux-lts using fallback initramfs\u0026#34; { loader /@/boot/vmlinuz-linux-lts initrd /@/boot/initramfs-linux-lts-fallback.img # linux-lts的备用initramfs } submenuentry \u0026#34;Boot to terminal\u0026#34; { add_options \u0026#34;systemd.unit=multi-user.target\u0026#34; # 进入终端 } # disabled # 注释掉disable才会生效 } 设定启动选项时需要在volume指定内核和initramfs的所处的子卷，volume的值可以设定成/或/boot所处的子卷标签或者GUID。\n查看子卷标签\n1 2 3 4 5 6 7 8 9 10 11 ❯ sudo lsblk -o name,mountpoint,label,size,uuid NAME MOUNTP LABEL SIZE UUID nvme0n1 476.9G ├─nvme0n1p1 SYSTEM_DRV 260M C2B6-5B79 ├─nvme0n1p2 16M ├─nvme0n1p3 Windows-SSD 175.7G 9292B82A92B81527 ├─nvme0n1p4 Windows 50G B88EF24F8EF20622 ├─nvme0n1p5 WINRE_DRV 1000M D800BC7600BC5CE6 ├─nvme0n1p6 /home arch 239.5G d26ed334-68d4-481d-894f-838783fa4f88 ├─nvme0n1p7 [SWAP] 10G d5792b35-68e7-421d-8dde-365e39e6a92b └─nvme0n1p8 /efi 512M 6CB0-E267 系统启动时会通过Boot Loader加载内核和ramfs，一般还要指定加载微码。内核文件vmlinuz-linux、内核对应的initramfs-linux.img以及微码intel-ucode.img默认位于/boot文件夹，在rEFInd配置时需要确定自己系统中这些文件实际存在的路径。\nArch Linux启动过程参考Arch boot process。\n保存对/efi/EFI/refind/refind.conf更改，此时重启进入rEFInd界面，会多出一个我们刚才定义的启动项，直接选择此项启动会直接加载linux内核，按F2进入此启动项的子选单会出现我们刚才定义的加载fallback initramfs和加载linux-lts内核等选项。选中原先的Arch Linux启动项按Delete隐藏即可。\n","date":"2023-07-09T14:10:06+08:00","image":"https://xland.cyou/p/arch-linux-configuration-driver-and-software/arch.webp","permalink":"https://xland.cyou/p/arch-linux-configuration-linux-lts-kernel/","title":"Arch Linux 配置 -- 安装linux-lts备用内核"},{"content":"最近趁着假期把Manjaro换成了Arch Linux，本文记录了我安装Arch Linux中的一些配置。\nArch Linux安装 安装教程参考archlinux 简明指南和ArchWiki。\n安装显卡驱动 本人电脑是联想小新Air13 IWL，有一个Intel核显和一个Nvidia独显。\n运行lspci -k | grep -A 2 -E \u0026quot;(VGA|3D)\u0026quot;可以查看显卡信息\n1 2 3 4 5 6 7 00:02.0 VGA compatible controller: Intel Corporation WhiskeyLake-U GT2 [UHD Graphics 620] Subsystem: Lenovo WhiskeyLake-U GT2 [UHD Graphics 620] Kernel driver in use: i915 -- 03:00.0 3D controller: NVIDIA Corporation GP108M [GeForce MX150] (rev a1) Subsystem: Lenovo GP108M [GeForce MX150] Kernel driver in use: nvidia Intel 驱动 参考ArchWiki-Intel graphics。\n首先安装mesa，它提供了用于3D加速得DRI驱动。对于Intel 8代以及更新的硬件选择软件包mesa，对于7代以及更老的芯片选择mesa-amber。\n为了支持32位程序，同时安装对应的lib32-mesa或者lib32-mesa-amber。 为了Vulkan支持，还需要安装vulkan-intel，以及32位支持包lib32-vulkan-intel。\n1 sudo pacman -S mesa lib32-mesa vulkan-intel lib32-vulkan-intel Nvidia 驱动 建议对照ArchWiki-NVIDIA安装，官方教程更加准确并且可能有更新。\n对于新于 Turing (NV160/TU_XXX_)系列的显卡，如果系统使用linux内核则安装nvidia-open，如果使用其他内核则安装nvidia-open-dkms。 对于较旧且新于 Maxwell (NV110/GM_XXX_)系列的显卡，如果使用linux内核则安装nvidia，如果使用linux-lts内核则安装nvidia-lts，其他内核则安装nvidia-dkms。 Kepler (NVE0/GK_XXX_)系列显卡，安装nvidia-470xx-dkms。 更旧的显卡安装开源驱动nouveau。 如果需要32位应用支持，还需安装lib32-nvidia-utils。同时可以安装nvidia-settings用来对nvidia驱动进行一些配置。\n1 sudo pacman -S nvidia nvidia-settings lib32-nvidia-utils 不同型号的显卡对应的软件包选择可以参考archlinux 简明指南-显卡驱动，最好同时对照ArchWiki选择。\n安装好驱动后，编辑/etc/mkinitcpio.conf，删去HOOKS那一项中得kms，阻止内核启动时加载nouveau。\n1 2 # HOOKS=(base udev autodetect modconf keyboard keymap kms consolefont block filesystems fsck) # 更改前 HOOKS=(base udev autodetect modconf keyboard keymap consolefont block filesystems fsck) # 更改后 更改后重新生成initramfs\n1 sudo mkinitcpio -P 重启系统，打开nvidia-settings如果可以看到显卡的各种详细信息，则说明安装成功。\n核显和独显动态切换 参考双显卡（核显 + 独显） 。\n安装optimus-manager，它提供了双显卡下切换仅用核显、仅用独显和动态切换三种模式，optimus-manager-qt则提供了模式切换的图形界面。\n1 yay -S optimus-manager optimus-manager-qt 启用视频硬件加速 参考ArchWiki-Hardware video acceleration。\n首先安装驱动\n1 sudo pacman -S intel-media-driver 不同型号的显卡需要安装的驱动包不同，具体要求可以查看ArchWiki。\n此时可以使用MPV播放视频检验硬件加速是否启用\n1 2 3 4 5 6 7 ❯ mpv --hwdec=auto test.mp4 (+) Video --vid=1 (*) (h264 1920x1080 29.970fps) (+) Audio --aid=1 (*) (aac 2ch 44100Hz) Using hardware decoding (vaapi). AO: [pulse] 44100Hz stereo 2ch float VO: [gpu] 1920x1080 vaapi[nv12] AV: 00:00:02 / 00:03:49 (1%) A-V: 0.000 从终端输出可以看到，此时硬件解码是正常的。\n在浏览器中启用视频硬件加速参考[HowTo] Enable Hardware Video Acceleration / Video Decode In Google Chrome, Brave, Vivaldi And Opera Browsers。以我使用的Vivaldi浏览器为例，只需要新建文件~/.config/vivaldi-stable.conf，在其中写入\n1 2 3 4 5 --use-gl=angle --ignore-gpu-blocklist --enable-features=VaapiVideoEncoder,VaapiVideoDecoder,CanvasOopRasterization --disable-features=UseChromeOSDirectVideoDecoder,UseSkiaRenderer --disable-gpu-driver-workarounds 此时在浏览器中进入vivaldi:gpu，已经正常启用了硬件加速。\nWindows 和 Linux 共用蓝牙 安装双系统后，每次切换系统都需要重新配对蓝牙设备。但是可以通过改变Linux系统中蓝牙设备的配对参数，实现两个系统共用一个蓝牙配对，这些切换系统后旧不用重新配对，直接可以自动连接蓝牙了。\n首先在Linux里配对蓝牙设备，然后重启进入Windows重新配对蓝牙。\n下载PSEXEC，以管理员身份启动终端，进入PSEXEC解压后的文件夹，运行\n1 ./psexec.exe -s -i regedit 在打开的页面中展开HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\BTHPORT\\Parameters\\Keys，里面有一个以Windows蓝牙控制器的MAC地址命名的文件夹，打开该文件夹，里面的文件夹名对应的是蓝牙设备的MAC地址，记下蓝牙设备的MAC地址和里面注册表的值。\n重启进入Linux，进入/var/lib/bluetooth，其中有一个以Linux蓝牙管理器MAC地址命名的文件夹，进入该文件夹，里面的文件夹以蓝牙设备的MAC地址命令，把这个文件夹重命名为和Windows中相同的MAC地址值。例如在我的电脑中，Windows中MAC地址为ffa68a9feeb2，在Linux中就改为FF:A6:8A:9F:EE:B2。\n1 2 3 4 5 6 7 F8:A2:D6:C9:7C:10 # Linux蓝牙管理器MAC地址 ├── cache │ └── FF:A6:8A:9F:EE:B2 ├── FF:A6:8A:9F:EE:B2 # 蓝牙设备MAC地址，改成和Windows相同的值 │ ├── attributes │ └── info └── settings 然后编辑FF:A6:8A:9F:EE:B2中的info文件，将相关的蓝牙配对参数改为和Windows相同，需要更改的值如下\n1 2 3 4 5 6 7 8 9 10 11 [LocalSignatureKey] Key=E03086C6AAAB88CF623E57F2361E6488 # 和Windows中CSRK相同 Counter=0 Authenticated=false [LongTermKey] Key=4BA30A70E71C729CC23D12EF29B8C889 # 和Windows中LTK相同 Authenticated=0 EncSize=16 EDiv=11107 # 和Windows中EDIV相同 Rand=12409689061704920446 # 和Windows中ERand相同 重启蓝牙，蓝牙设备就会自动连接\n1 sudo systemctl restart bluetooth 使用rEFInd引导系统 rEFInd是一个适用于UEFI的Boot Manager，支持自定义主题，可以替代界面简陋的GRUB，用来引导Linux和Windows双系统。 rEFInd和GRUB的关系可以参考这里。首先安装rEFInd软件包\n1 sudo pacman -S refind 将rEFInd引导文件安装到ESP分区\n1 refind-install 配置rEFInd主题，我选择的主题是refind-theme-regular，自动安装命令如下\n1 sudo bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/bobafetthotmail/refind-theme-regular/master/install.sh)\u0026#34; 官方默认安装主题到/boot/efi/EFI/refind/themes/refind-theme-regular/theme.conf，如果在安装Arch时选择将ESP分区挂在在/efi的话，需要按照官方的手动安装指导将主题安装到/efi/EFI/refind/themes/refind-theme-regular/theme.conf。 最终的主题效果如下\n如果引导页面有多余项的话，可以按键盘上的Delete键隐藏该启动项。如果未出现rEFInd引导页，可以在电脑的BIOS设置界面将rEFInd启动项置顶。\n安装MATLAB 我在安装时采用的是MATLAB 2022a安装包，在终端运行安装脚本，出现报错\n1 /home/xu/Downloads/R2022a_Linux/bin/glnxa64/MathWorksProductInstaller: error while loading shared libraries: libcrypt.so.1: cannot open shared object file: No such file or directory 这是由于系统缺少libxcrypt，使用pacman安装相应软件包\n1 sudo pacman -S libxcrypt-compat 再次运行安装脚本，出现报错信息\n1 2 3 terminate called after throwing an instance of \u0026#39;std::runtime_error\u0026#39; what(): Failed to launch web window with error: Unable to launch the MATLABWindow application. The exit code was: 127 [1] 3019 IOT instruction (core dumped) ./install 此时可以按照ArchWiki-MATLAB中的指导进行排查错误来源，为了找出为何MATLABWindow无法加载，在MATLAB安装文件中执行以下命令，查看输出的报错信息\n1 2 ./bin/glnxa64/MATLABWindow ./bin/glnxa64/MATLABWindow: error while loading shared libraries: libgtk-x11-2.0.so.0: cannot open shared object file: No such file or directory 可以看到系统中无法找到libgtk-x11-2.0.so.0，安装缺失的软件包\n1 sudo pacman gtk2 再次运行./bin/glnxa64/MATLABWindow，出现错误信息\n1 ./bin/glnxa64/MATLABWindow: symbol lookup error: /usr/lib/libharfbuzz.so.0: undefined symbol: FT_Get_Color_Glyph_Layer 此时的报错信息已经和ArchWiki一致，按照说明添加环境变量，再次运行安装脚本\n1 2 export LD_PRELOAD=/lib64/libfreetype.so ./install 这时MATLAB安装界面可以正常运行，正常安装即可。\n如果在MATLAB运行时碰到问题，可以参考我之前写的Manjaro Linux 安装 MATLAB，里面记录了诸如设置无法保存、无法开启OpenGL加速等各种问题。\n","date":"2023-07-08T17:40:07+08:00","image":"https://xland.cyou/p/arch-linux-configuration-driver-and-software/arch.webp","permalink":"https://xland.cyou/p/arch-linux-configuration-driver-and-software/","title":"Arch Linux 配置 -- 驱动和软件安装"},{"content":"背景 传统的 MUSIC 算法和 ESPRIT 算法都指利用了接收信号的二阶累计量，这些算法的缺点主要有：\n对于一个具有 N 个阵元的阵列，可估计的信号数最大为 N-1 当阵列模型存在误差（eg. 算法中使用的流型矩阵和实际的流型矩阵不符），或者阵元接受到的噪声存在相关性的情况下，算法的鲁棒性很差 在较小快拍数下，对于角度邻近的信号估计精度较差 基于高阶累计量（Higher-order Cumulants）的 DOA 估计算法早期被用于处理不同阵元接收到的高斯噪声存在相关性的情况，随着研究的深入，人们发现高阶累积量的引入提高了阵列的可估计信号数和分辨率，同时对阵列模型误差存在一定的校正。 使用二阶累积量面临的问题 对于阵列接受信号 $${\\bf{X}}(t) = {\\bf{AS}}(t) + {\\bf{N}}(t)$$ 一般的子空间类分解算法是从接受信号的协方差矩阵，即二阶累积量组成的矩阵中提取角度信号 $${R_{xx}} = A{R_{ss}}A + {R_{nn}}$$ 其中$R_{nn}$表示接受噪声的协方差矩阵。如果噪声是高斯白噪声，那么$R_{nn}=\\sigma^2 I$，是一个对角元素等于噪声功率的对角阵，此时对$R_{xx}$做特征分解，可以得到\n$$ R_{xx} = \\begin{bmatrix}U_{s}\u0026amp;U_{n}\\end{bmatrix} \\begin{bmatrix} \\sigma_1^2+\\sigma^2\u0026amp;\u0026amp;\u0026amp; \\newline \u0026amp;\\sigma_2^2+\\sigma^2\u0026amp;\u0026amp; \\newline \u0026amp;\u0026amp;\\ddots\u0026amp; \\newline \u0026amp;\u0026amp;\u0026amp;\\sigma^2 \\end{bmatrix} \\begin{bmatrix} U_{s} \\newline U_{n}\\end{bmatrix} $$\n如果阵元接受到的噪声不是高斯白噪声，在 DOA 估计中主要表现为不同阵元接收到的噪声之间存在相关性，那么噪声的协方差矩阵$R_{nn}$不是一个对角阵，此时无法通过对接受信号协方差矩阵$R_{xx}$的特征分解确定信号子空间和噪声子空间。\n高阶累计量对 DOA 估计的意义 如果接受到的噪声不是高斯白噪声，那么噪声的协方差矩阵不是对角阵，无法分解出噪声子空间和信号子空间。根据高阶累积量的性质，高斯随机过程的四阶累积量为 0，如果接受噪声符合高斯随机分布，即使不同阵元接受到的噪声存在相关性，仍然可以通过四阶累积量构造新的协方差矩阵，实现去除噪声的目的。\n四阶累积量的计算 对于一个$N\\times 1$的实数值矢量 x，它的第 q 阶累积量可以由它的矩表示\n$$Cum[{x_{{i_1}}},{x_{{i_2}}}, \\ldots ,{x_{{i_q}}}] = \\sum\\limits_{p = 1}^q {{{( - 1)}^{p - 1}}(p - 1)!E{ \\prod\\limits_{j \\in {S_1}} {{x_{ij}}} } } E{ \\prod\\limits_{j \\in {S_2}} {{x_{ij}}} } \\cdots E{ \\prod\\limits_{j \\in {S_2}} {{x_{ij}}} } $$\n对于一个零均值的矢量x，它的二阶、三阶和四阶累计量可以写成 $$Cum[{x_i},{x_j}] = E{ {x_i}{x_j}} $$ $$Cum[{x_i},{x_j},{x_k}] = E{ {x_i}{x_j}{x_k}} $$ $$Cum[{x_i},{x_j},{x_k},{x_l}] = E{ {x_i}{x_j}{x_k}{x_l}} - E{ {x_i}{x_j}} E{ {x_k}{x_l}} - E{ {x_i}{x_k}} E{ {x_j}{x_l}} - E{ {x_i}{x_l}} E{ {x_j}{x_k}} $$\n基于高阶累积量的 DOA 估计 接受信号模型 考虑一个具有 N 个阵元的阵列，阵列接收到 P 个入射信号（P 的个数可以大于或等于 N）。我们把 P 个信号划分成 G 组，其中第 g 组包含的信号数表示成$P_g$。位于同一组的信号不独立但也不相干，位于不同组的信号相互独立。此时可以写出阵元接受信号的数学模型 $$\\bf{x_g}(t) = \\bf{A_g}\\bf{s_g}(t)$$ $${\\bf{y}}(t) = \\sum\\limits_{g = 1}^G {{{\\bf{A}}_g}{{\\bf{S}}_g}(t) + {\\bf{w}}(t)} $$ 其中${{{\\bf{S}}_g}(t)}$表示第 g 组入射信号复振幅，${{{\\bf{A}}_g}}$表示第 g 组的入射信号对应流型矩阵。${{\\bf{w}}(t)}$表示阵元接收到的噪声，假设该噪声符合高斯分布，不同阵元接受到的噪声之间存在相关性。\n基于四阶累计量的 MUSIC 算法（MUSIC-Like Algorithm based on FO Cumulant） 在求接收信号的四阶累积量时，采用复数形式的定义式\n$$Cum[y_i,y_j,y_{k}^{*},y_{l}^{*}] = E\\{ y_i,y_j,y_k^*,y_l^*\\} -E\\{ y_i,y_j\\} E\\{ y_k^*,y_l^*\\} - E\\{ y_i,y_k^*\\} E\\{ y_j,y_l^*\\} - E\\{ y_i,y_l^*\\} E\\{ y_j,y_k^*\\}$$\r一般使用近似公式求解四阶矩和二阶矩 $$E\\{ {y_i},{y_j},y_k^*,y_l^*\\} = {1 \\over L}\\sum\\limits_{t = 1}^L {{y_i}(t){y_j}(t)y_k^*(t)y_l^*(t)} $$\r$$E{ {yi},{y_j}} = {1 \\over L}\\sum\\limits{t = 1}^L {{y_i}(t){y_j}(t)} $$ 按照上述四阶累积量的近似计算公式计算$x_g(t)$的四阶累积量，如果取四阶累积量的下标i、j、k、l为不同值，总共可以求出$N^2\\times N^2$个不同的四阶累计量，把它们写成一个$N^2\\times N^2$维矩阵$C_g$的形式，每个四阶累积量作为$C_g$的一个元素。其中 $${C_g}[(i - 1)N \u0026#43; k,(j - 1)M \u0026#43; l] = Cum[{y_i},{y_j},y_k^*,y_l^*]$$\r于是有 $${{\\bf{C}}_g} = ({{\\bf{A}}_g} \\otimes {\\bf{A}}_g^*){{\\bf{S}}_g}{({{\\bf{A}}_g} \\otimes {\\bf{A}}_g^*)^H}$$\r其中 $$\\begin{split} S_g \u0026amp;= E\\{(s_g(t)\\otimes s_g^*(t)) (s_g(t)\\otimes s_g^*(t))^H\\} \\newline \u0026amp;- E\\{s_g(t)\\otimes s_g^*(t)\\} E\\{(s_g(t)\\otimes s_g^*(t))^H\\} \\newline \u0026amp;- E\\{s_g(t)\\otimes s_g^H(t)\\} E\\{s_g(t)\\otimes s_g^H(t)\\}\\end{split}$$\r$S_g$表示第 g 组的接受信号的四阶累积量组成的$N^2\\times N^2$维矩阵。\n性质 1：如果随机变量$x_i$和$y_i$相互独立，那么有 $$cum\\{x_1\u0026#43;y_1,x_2\u0026#43;y_2,\\dots,x_n \u0026#43;y_n\\}=cum\\{x_1,x_2,\\dots,x_n\\} \u0026#43;cum\\{y_1,y_2,\\dots,y_n\\}$$\r性质 2：如果 x 是一个高斯随机过程，则它的高阶累积量（$k\\ge2$)恒等于 0\n由上述两个性质可得，在阵元接受到的噪声为高斯噪声的情况下，阵元接受数据 y(t)的四阶累积量组成的$N^2\\times N^2$维矩阵 C 为 $$C = \\sum\\limits_{g = 1}^G {{C_g}} $$ $$C=\\begin{bmatrix}A*1\\otimes A_1^*,\\dots,A_G\\otimes A_G^*\\end{bmatrix}\r\\begin{bmatrix}S_1\u0026amp;\\dots\u0026amp;0\\newline \\vdots\u0026amp;\\ddots\u0026amp;\\vdots \\newline 0\u0026amp; \\dots\u0026amp;S_G \\end{bmatrix}\r\\begin{bmatrix}(A_1\\otimes A_1)^H \\newline \\vdots \\newline (A_G\\otimes A_G)^H\\end{bmatrix}$$\r由于第g组内的入射信号互相不独立，$S_g$是满秩矩阵，所以$C_g$的秩为$N_g^2$，于是矩阵C的秩为$\\sum\\limits*{g = 1}^G {N_g^2 \u0026lt; {N^2}}$。如果G=1，即所有接受信号互相不独立，那么C的秩为$N^2$；如果 G=P，即所有接受信号互相独立，C 的秩为 N。对 C 做奇异值分解\n$$ C=\\begin{bmatrix}U_1\u0026amp;U_2\\end{bmatrix} \\begin{bmatrix}\\Lambda\u0026amp;0 \\newline 0\u0026amp;0\\end{bmatrix} \\begin{bmatrix}V_1^H \\newline V_2^H\\end{bmatrix} $$\n其中$\\Lambda$是一个$\\sum\\limits_{g = 1}^G {N_g^2}$维对角阵，于是可以根据 C 的奇异值中 0 元素对应的特征向量确定子空间$U_2$。\n由于${A_g} \\otimes A_g^*$\r与$U_2$正交，可以确定与入射信号角度对应的导向矢量满足 $${[a(\\theta ) \\otimes {a^*}(\\theta )]^H}{U_2} = 0$$\r此时可以构造出类似于 MUSIC 算法的空间谱 $$P(\\theta ) = {1 \\over {||{{[a(\\theta ) \\otimes {a^*}(\\theta )]}^H}{U_2}|{|^2}}}$$ 优缺点：可以应用于接受信号互相不独立（不能完全相关）或者不同阵元接收到的噪声之间存在相关性（高斯噪声）的场景。提高了 DOA 估计的分辨率和最大可估计信号数。\n计算量较大，需要计算$N^4$个四阶累积量。对于信源发射信号不独立的情况，需要预先知道信号的分组情况来确定 C 的非零特征值数目。\n四阶累积量带来的阵列扩展 对于一个任意阵列，以第一个阵元作为参考阵元，它的阵元位置可以表示成 $$[0,{\\vec d_1},{\\vec d_2}, \\ldots ,{\\vec d_{M-1}}]$$ 阵列接收到的信号可以写成 $$\\bf{X}(t)=\\begin{bmatrix}s(t)\u0026amp;s(t)exp(-j\\vec{d}_1 \\cdot \\vec{k})\u0026amp;\\dots\u0026amp;s(t)exp(-j\\vec{d}_{M-1}\\cdot\\vec{k})\\end{bmatrix}^T$$\r其中$\\vec k = {{2\\pi f} \\over c}{\\vec k_n}$，${\\vec k_n}$表示入射信号方向的单位向量。\n接受信号的二阶累积量为\n$${\\mu _{l,k}} = cum({x_l}(t),{x_k}(t)) = E\\{ {x_l}^*(t),{x_k}(t)\\} = \\sigma _s^2\\exp ( ({\\vec d_l} - {\\vec d_k}) \\cdot \\vec k)$$\r接受信号的协方差矩阵为\n$$ \\bf{R}=\\begin{bmatrix} \\mu_{0,0}\u0026amp;\\mu_{0,1}\u0026amp;\\dots\u0026amp;\\mu_{0,M-1}\\newline \\mu_{1,0}\u0026amp;\\mu_{1,1}\u0026amp;\\dots\u0026amp;\\mu_{1,M-1}\\newline \\vdots\u0026amp;\\vdots\u0026amp;\\ddots\u0026amp;\\vdots\\newline \\mu_{M-1,0}\u0026amp;\\mu_{M-1,1}\u0026amp;\\dots\u0026amp;\\mu_{M-1,M-1}\\newline \\end{bmatrix} $$\n信号入射到任意阵列\n图中$r(t),x(t),y(t)$表示三个阵元接受到的信号，其中以$r(t)$处作为参考阵元，即$r(t)=s(t)$，图中$v(t)$表示离$r(t)$为$\\vec d$的某点接受到的信号 $$v(t) = s(t)\\exp ( - j\\vec k \\cdot \\vec d)$$ $r(t)$和$v(t)$组成的二阶累积量为 $${\\mu _{r,v}} = E\\{ {r^*}(t)v(t)\\} = \\sigma _s^2\\exp ( - j\\vec d \\cdot \\vec k)$$\r$r(t),x(t),y(t)$组成的一种四阶累积量 $$\\begin{split}\r\\mu_{r,x}^{r,y}\u0026amp;=cum\\{r^*(t),x(t),r^*(t),y(t)\\}\\newline\r\u0026amp;=cum\\{s(t),s(t),s(t),s(t)\\}exp(-j(\\vec{d}_x\u0026#43;\\vec{d}_y)\\cdot\\vec{k})\\newline\r\u0026amp;=\\gamma_{4,s}exp(-j\\vec{d}\\cdot\\vec{k})\r\\end{split}$$\r所以我们可以得到四阶累积量和二阶累积量的关系 $$E\\{ {r^*}(t)v(t)\\}=\\frac{\\sigma_s^2}{\\gamma_{4,s}}cum\\{ {r^*}(t),x(t),{r^*}(t),y(t)\\}$$\r$${\\mu _{r,v}}=\\frac{\\sigma_s^2}{\\gamma_{4,s}}\\mu _{r,x}^{r,y}$$\r也即是说，通过求实际阵元$r,x,y$的四阶累积量，我们得到虚拟阵元 v 和实际阵元 s 之间的二阶累积量。并且它们在集合上有如下关系 $$\\overrightarrow {rv} = \\overrightarrow {rx} + \\overrightarrow {ry} $$\n同理可以得到 $$E\\{ {r^*}(t)y(t)\\} = {{\\sigma _s^2} \\over {{\\gamma _{4,s}}}}cum\\{ {r^*}(t),y(t),{r^*}(t),r(t)\\} $$\r$$E\\{ {y^_}(t){v*4}(t)\\} = {{\\sigma \\_s^2} \\over {{\\gamma *{4,s}}}}cum\\{ {y^_}(t),r(t),{y^_}(t),x(t)\\} $$\r$$E\\{ {v_1}^_(t){v*3}(t)\\} = {{\\sigma \\_s^2} \\over {{\\gamma *{4,s}}}}cum\\{ {y^_}(t),x(t),{y^_}(t),r(t)\\} $$\r在前面所讨论的基于四阶累计量的MUSIC算法中，我们用接受数据的四阶累积量组成了一个$M^2\\times M^2$维的矩阵C，C中每一个元素都是由4个阵元的接受数据组成的四阶累积量$cum[{y_i},{y_j},y_k^*,y_l^*]$\r。\n实际上它是对原本的M个阵元进行了扩展得到了一个虚拟阵列，每一个四阶累积量对应了经过这个虚拟阵列中两个阵元的接受数据组成的二阶累积量。所以$M^2\\times M^2$维的矩阵C实际上是经过扩展后的虚拟阵列的协方差矩阵。\n四阶累积量组成的$M^2\\times M^2$维的矩阵C为 $${{\\bf{C}}} = ({{\\bf{A}}} \\otimes {\\bf{A}}^_){{\\bf{S}}}{({{\\bf{A}}} \\otimes {\\bf{A}}^_)^H}$$\r此时的流型矩阵为 $$\\bf{A}\\otimes\\bf{A}^_=\\begin{bmatrix}a(\\theta_1)\\otimes a^_(\\theta_1)\u0026amp;\\dots\u0026amp;a(\\theta_N)\\otimes a^\\*(\\theta_N) \\end{bmatrix}$$\r以一个三阵元的阵列为例，三个实际存在的阵元分别为$r,y,x$，经过四阶累积量扩展后的流型矩阵为 $$\\begin{split}b(\\theta)\u0026amp;=a(\\theta)\\otimes a^*(\\theta)\\newline\r\u0026amp;=\\begin{bmatrix}1\u0026amp;exp(-jk\\vec{d}_x)\u0026amp;exp(-jk\\vec{d}_y)\\end{bmatrix}^T\\otimes\r\\begin{bmatrix}1\u0026amp;exp(jk\\vec{d}_x)\u0026amp;exp(jk\\vec{d}_y)\\end{bmatrix}^T\\newline\r\u0026amp;=\\begin{bmatrix}1\u0026amp;exp(jk\\vec{d}_x)\u0026amp;exp(jk\\vec{d}_y)\u0026amp;exp(-jk\\vec{d}_y)\u0026amp;1\u0026amp;exp(-jk(\\vec{d}_x-\\vec{d}_y))\u0026amp;exp(-jk\\vec{d}_y)\u0026amp;exp(-jk(\\vec{d}_y-\\vec{d}_x))\u0026amp;1\\end{bmatrix}^T\r\\end{split}$$\r可以看出此时 3 个阵元的阵列经过四阶累积量扩展，得到的流型矩阵扩展为 9 个元素，其中除了实际存在的 3 个阵元外，还有 4 个虚拟阵元。\n对于某些结构的阵列，经过四阶累积量的扩展，相当于加入了虚拟阵元，从而提升可估计的信号个数，提高了 DOA 估计算法的分辨率。\n","date":"2023-03-25T11:26:43+08:00","permalink":"https://xland.cyou/p/higer-order-statistics-doa-estimation/","title":"基于高阶累积量的DOA估计"},{"content":"最近从 Windows 换到了 Manjaro，日常离不开 MATLAB，虽然 MATLAB 官方提供了 Linux 版本，但是没有对 Manjaro 做适配，所以在安装 MATLAB 的过程中遇到了各种问题，以此记录。任何其他问题建议查阅ArchWiki。\nMATLAB 安装报错 最初安装的时候，我下载的是 MATLAB 2020b 的 iso 镜像，即使按照 ArchWiki 的指导，移除了libfreetype.so*还是会继续报错。后来换成 MATLAB 2022a 的镜像才成功安装。\n进入 MATLAB 2022a 安装文件所处的文件夹，运行./install，出现报错\n1 2 3 terminate called after throwing an instance of \u0026#39;std::runtime_error\u0026#39; what(): Failed to launch web window with error: Unable to launch the MATLABWindow application. The exit code was: 127 [1] IOT instruction (core dumped) ./install 此时可以运行\n1 ./bin/glnxa64/MATLABWindow 应该会出现报错信息\n1 bin/glnxa64/MATLABWindow: symbol lookup error: /usr/lib/libcairo.so.2: undefined symbol: FT_Get_Color_Glyph_Layer FT_Get_Color_Glyph_Layer是 freetype2 里的一个符号，只要删除 MATLAB 安装文件夹里的libfreetype.so*，执行\n1 rm ./bin/glnxa64/libfreetype.so* 或者也可以添加环境变量\n1 LD_PRELOAD=/lib64/libfreetype.so 此时再执行./install就可以成功打开 MATLAB 安装引导。\n解决方案来源：ArchWiki-MATLAB\nMATLAB 界面内中文无法显示 安装完成，打开 MATLAB 却发现中文乱码，所有的中文都是方块。MATLAB 的界面是用 JAVA 开发的，中文无法显示是因为 JAVA 的中文字体配置问题。\n此时进入 MATLAB 的安装路径下的 jre 目录，我的 MATLAB 安装在/usr/local/MATLAB/R2022a，进入该文件夹\n1 cd /usr/local/MATLAB/R2022a/sys/java/jre/glnxa64/jre/lib/fonts 在此目录下新建fallback文件夹\n1 mkdir fallback 将中文字体移动到 fallback 文件夹，我使用的字体是 NotoSansCJK-Regular.ttc，想要获取改字体可以先运行sudo pacman noto-fonts-cjk，然后在/usr/share/fonts/noto-cjk就可找到字体文件。\n1 sudo cp /usr/share/fonts/noto-cjk/NotoSansCJK-Regular.ttc /usr/local/MATLAB/R2022a/sys/java/jre/glnxa64/jre/lib/fonts/fallback 复制完字体文件后，在fallback文件夹内，运行\n1 mkfontscale 此时会生成fonts.scale，打开fonts.scale，将其中内容复制到上级目录/usr/local/MATLAB/R2022a/sys/java/jre/glnxa64/jre/lib/fonts中的fonts.dir\n注意fonts.dir没有可写权限，需要先授予可写权限\n1 sudo chmod 6 fonts.dir 此时进入 MATLAB 就可以正常显示中文了。\n解决方案来源：Linux 下 Matlab 的安装和中文显示支持。\n如果 MATLAB 的终端无法显示中文，可以在 MATLAB 内主页-预设-字体下的两个字体选项里选择中文字体（如果设置无法保存请参考下节）。\nMATLAB 的设置无法保存 在 MATLAB 的设置界面更改设置选项，发现退出 MATLAB 后在重新打开，所有的设置会恢复默认值，这是因为 MATLAB 无法使用/tmp 文件夹。新建文件夹\n1 mkdir ~/.cache/matlab-tmp 在/home/xuq/.local/share/applications为 MATLAB 建立一个启动方式matlab.desktop，文件内容为\n1 2 3 4 5 6 7 8 [Desktop Entry] Type=Application Version=R2022b Name=MATLAB Comment=Scientific computing software Icon=/home/\u0026lt;username\u0026gt;/.local/share/applications/matlab_logo.png Exec=bash -c \u0026#34;export TMPDIR=/home/\u0026lt;username\u0026gt;/.cache/matlab-tmp; /usr/local/MATLAB/R2022a/bin/glnxa64/MATLAB -desktop; rm -r $TMPDIR\u0026#34; Terminal=False 注意替换 MATLAB 可执行文件的路径，以及 MATLAB 的 Icon 路径。\n解决方案来源：Why aren\u0026rsquo;t my MATLAB preferences saved on Linux?。\nMATLAB 无法打开文本编辑器 在 MATLAB 中新建脚本或者打开脚本时，出现报错Unable to open this file in the current system configuration，终端输出\n1 2 3 4 5 6 7 8 9 Exception in thread \u0026#34;AWT-EventQueue-0\u0026#34;: java.lang.NullPointerException at com.mathworks.mde.desk.MLDesktop.updateTemplate(MLDesktop.java:3665) at com.mathworks.mde.desk.MLDesktop.access$2000(MLDesktop.java:225) at com.mathworks.mde.desk.MLDesktop$NewMFileAction.actionPerformed(MLDesktop.java:2853) at com.mathworks.mwswing.ChildAction.actionPerformed(ChildAction.java:214) at javax.swing.AbstractButton.fireActionPerformed(AbstractButton.java:2022) at javax.swing.AbstractButton$Handler.actionPerformed(AbstractButton.java:2348) at javax.swing.DefaultButtonModel.fireActionPerformed(DefaultButtonModel.java:402) ...... 此时只需要进入 MATLAB 的安装路径，去除libfreetype.so.6\n1 2 cd /usr/local/MATLAB/R2022a/bin/glnxa64 mv libfreetype.so.6 libfreetype.so.6.old 解决方案来源：MATLAB cannot create or open script files。\nMATLAB 界面缩放过小 MATLAB 的界面、字体和图标在 Linux 下很小，无法随着系统缩放而改变。 以 MATLAB 界面放大 1.25 倍为例，在 MATLAB 终端输入\n1 2 \u0026gt;\u0026gt; s = settings;s.matlab.desktop.DisplayScaleFactor \u0026gt;\u0026gt; s.matlab.desktop.DisplayScaleFactor.PersonalValue = 1.25 解决方案来源：Does MATLAB support High DPI screens on Linux?。\nMATLAB 无法使用 OpenGL 加速 MATLAB 绘图时终端输出\n1 2 3 4 Warning: MATLAB previously crashed due to a low-level graphics error. To prevent another crash in this session, MATLAB is using software OpenGL instead of using your graphics hardware. To save this setting for future sessions, use the opengl(\u0026#39;save\u0026#39;, \u0026#39;software\u0026#39;) command. For more information, see Resolving Low-Level Graphics Issues. 设置由于 MATLAB 无法使用 OpenGL 硬件加速，导致图形渲染能力下降，在 3D 绘图时可能出错。\n进入 MATLAB 可执行文件所在的路径\n1 2 cd /usr/local/MATLAB/R2022a/bin/glnxa64 MATLAB -nodesktop -nosplash -r \u0026#34;opengl info; exit\u0026#34; | grep Software 如果终端中输出的software rendering值不是false（0 也不行）,说明此时未启用硬件加速。查看系统的 OpenGL 配置\n1 glxinfo | grep \u0026#34;direct rendering\u0026#34; 如果direct rendering的值为yes说明配置正确，否则先要解决 OpenGL 的系统配置。如果系统的 OpenGL 配置正确，更改先前创建的 MATLAB 启动方式，在/home/xuq/.local/share/applications打开matlab.desktop，在 Exec 项添加 MATLAB 运行时的环境变量，将其更改为\n1 Exec=bash -c \u0026#34;export TMPDIR=/home/xuq/.config/matlab-temp; export LD_PRELOAD=/usr/lib/libstdc++.so; export LD_LIBRARY_PATH=/usr/lib/dri/; /usr/local/MATLAB/R2022a/bin/glnxa64/MATLAB -desktop; rm -r $TMPDIR\u0026#34; 然后在 MATLAB 可执行文件所在的路径下新建文件\n1 touch /usr/local/MATLAB/R2022a/bin/glnxa64/java.opts 在java.opts中写入-Djogl.disable.openglarbcontext=1。 解决方案来源：ArchWiki-MATLAB。\n","date":"2023-03-19T18:40:57+08:00","permalink":"https://xland.cyou/p/manjaro-linux-matlab/","title":"Manjaro Linux 安装 MATLAB"},{"content":"DOA 估计的模糊问题 一些经典的 DOA 估计算法，例如 MUSIC 算法，利用了阵列流型矩阵和噪声子空间的正交关系来确定入射信号的角度。因此在使用这些算法时，必须保证流型矩阵中各个导向矢量是线性无关的，这也是为什么要保证阵列天线的个数大于入射信号的个数。\n在讨论阵列的相位模糊时，如果某一个导向矢量可以表示成其他 K 个导向矢量的线性组合 $$a(\\phi_k,\\theta_k) = \\sum_{i = 1}^K l_ia(\\phi_i,\\theta_i), \\ \\ {l_i} \\ne 0$$ 则称该阵列存在K 阶模糊问题，此时会存在测向模糊。当$K=1$时，称一阶模糊或平凡模糊。\n高阶模糊的识别比较复杂，发生的条件也更加有限，一般只讨论一阶模糊的问题，即流型矩阵中的导向矢量存在 $$a({\\phi _i},{\\theta _i}) = a({\\phi _j},{\\theta _j}),\\ \\ i \\ne j$$\n均匀线阵的相位模糊 在讨论均匀线阵的模糊问题时，主要考虑阵元间距带来的相位模糊。\n设$\\theta$为实际的入射信号，如果存在$a(\\hat{\\theta})=a(\\theta)$，此时在运行 MUSIC 算法时，在$\\theta$和$\\hat{\\theta}$都会出现谱线峰值。\n在均匀线阵中 DOA 估计的角度范围为$[ - {\\pi \\over 2},{\\pi \\over 2}]$，根据导向矢量的表达式 $$a(\\theta ) = \\begin{bmatrix} e^{j\\omega {\\tau_0}} \u0026amp; e^{j\\omega {\\tau_1}} \u0026amp; \\dots \u0026amp; e^{j\\omega {\\tau_{M-1}}}\\end{bmatrix}$$ 一阶模糊出现的条件为 $$2\\pi \\frac{d}{\\lambda}sin\\hat{\\theta}=2\\pi \\frac{d}{\\lambda}sin\\theta+2k\\pi,\\ \\ k\\in Z$$ 其$d$为相邻两阵元的间距，化简得 $$sin\\hat{\\theta}=sin\\theta+\\frac{k}{d / \\lambda},\\ \\ k \\in Z$$ 根据$sin\\theta$在$[ - {\\pi \\over 2},{\\pi \\over 2}]$上的单调性，我们可以知道一阶模糊是否出现，等价于是否存在除零以外的整数 k 使得$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$。于是可以推导出均匀线阵出现一阶模糊的条件：\n$d\\le\\frac{1}{2}\\lambda$ 此时$|\\frac{k}{d/\\lambda}|\\ge 2|k|$，为使$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$，k 只能取 0。 $\\frac{1}{2}\\lambda\u0026lt;d\u0026lt;\\lambda$ 此时$2|k|\u0026gt;|\\frac{k}{d/\\lambda}|\u0026gt; |k|$，取$|k|=1$可得如果入射角满足$|sin\\theta|\u0026lt;\\lambda /d -1$，不会出现多余峰值；否则会出现一个虚假谱峰。 $d\\ge \\lambda$ 此时$|\\frac{k}{d/\\lambda}|\\le |k|$，为使$(sin\\theta+\\frac{k}{d / \\lambda})\\in[-1,1]$，当$0\\le sin\\theta \\le 1$时，k 至少还可以取-1；当$-1\\le sin\\theta \\le 0$时，k 至少还可以取 1，所以此时一定会出现虚假谱峰。 均匀圆阵的相位模糊 均匀圆阵的相位模糊问题，一般只出现在阵列孔径较大，而阵元数较少的情况下。\n考虑一维均匀圆阵，即只考虑方位角$\\theta$，俯仰角取 90 度。\n假设出现$a(\\hat{\\theta})=a(\\theta)$，则在第 m 个阵元上有 $$2\\pi\\frac{r}{\\lambda}cos(\\hat{\\theta}-(m-1)\\frac{2\\pi}{M})=2\\pi\\frac{r}{\\lambda}cos(\\theta-(m-1)\\frac{2\\pi}{M})+2k\\pi$$ 右式减左式可得 $$\\rho_m=\\frac{4\\pi r}{\\lambda}sin(\\frac{\\theta-\\hat{\\theta}}{2})sin(\\frac{\\theta+\\hat{\\theta}}{2}-(m-1)\\frac{2\\pi}{M})=2k\\pi,k\\in Z$$ 同理，在第 m+1 个阵元上可以得到 $$\\rho_{m+1}=\\frac{4\\pi r}{\\lambda}sin(\\frac{\\theta-\\hat{\\theta}}{2})sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})=2k\u0026rsquo;\\pi,k\\in Z$$ 所以 $$\\frac{\\rho_{m+1}}{\\rho_m}=sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})/sin(\\frac{\\theta+\\hat{\\theta}}{2}-(m-1)\\frac{2\\pi}{M})=\\frac{\\phi_m}{\\phi_{m+1}}=\\frac{k}{k\u0026rsquo;}$$ 即在存在一阶模糊时，上式的结果为有理数。\n根据三角函数的展开定理，可以将$\\phi_{m+1}$用$\\phi_m$表示 $$\\phi_{m+1}=sin(\\frac{\\theta+\\hat{\\theta}}{2}-m\\frac{2\\pi}{M})=\\phi_mcos\\frac{2\\pi}{M}-\\sqrt{1-\\phi_m^2}sin\\frac{2\\pi}{M}$$ 于是可以得到均匀圆阵出现一阶模糊的条件（必要条件）：当$M\\ge 5$且为奇数或者$M\\ge 8$且为偶数时，$cos\\frac{2\\pi}{M}$和$\\sin\\frac{2\\pi}{M}$为无理数，此时均匀圆阵不会出现一阶模糊。\n[1] 跃郭, 王宏远, 陬周, Yue G. U. O., Hong-yuan Wang 和 Zou Zhou. 《阵元间距对 MUSIC 算法的影响》. 电子学报 35, 期 9 (2007 年 9 月 25 日): 1675.\n[2] Xiao, Wei, Xian-Ci Xiao 和 Heng-Ming Tai. 《Rank-1 ambiguity DOA estimation of circular array with fewer sensors》. 收入 The 2002 45th Midwest Symposium on Circuits and Systems, 2002. MWSCAS-2002., 3:III–III, 2002.\n","date":"2023-02-25T15:54:25+08:00","permalink":"https://xland.cyou/p/uca-doa-ambiguity/","title":"DOA估计中均匀圆阵的模糊问题"},{"content":"ChromeOS是Google推出的桌面操作系统，主打基于云应用的轻量操作系统，如今的ChromeOS已经支持Linux模式和直接运行Android应用。由于Google没有开放系统给Chromebook以外的设备，一般电脑安装ChromeOS可以借助开源项目brunch。\nbrunch能够利用ChromeOS的recovery文件，生成可用的系统镜像文件，从而在非Chromebook上安装原生ChromeOS。\n硬件要求 x86_64架构，UEFI启动模式 Intel CPU至少第四代，或者AMD Ryzen 不支持独显，不支持虚拟机，不支持Arm 可以安装Linux子系统（WSL2）的Windows或者Linux系统 空闲空间至少有16G 安装ChromeOS到U盘 下载ChromeOS recovery文件。\n参考自己的CPU型号，选择一个和自己电脑配置接近的chrome设备，在Chromium Dash下载该设备的recovery文件，一般选择最新的发行版本即可。\n我选择的是Lenovo Yoga C630 Chromebook，codename为pantheon，下载发行版本为109的recovery文件。\n如果不知道应该下载哪个recovery，brunch的项目文档里也给了推荐的recovery。\nIntel 1代-9代：选择codename为rammus的设备对应的recovery 10代和11代：选择codename为volteer的设备对应的recovery AMD Ryzen：选择codename为zork的设备对应的recovery 下载brunch的release文件\n在brunch的release页面下载和recovery版本号对应的文件，例如下载的recovery为109，则下载Brunch r109。\n制作ChromeOS镜像文件\n将下载好的Brunch和ChromeOS recovery放在一个文件夹，分别解压。\n打开WSL终端，安装必要软件。\n1 sudo apt update \u0026amp;\u0026amp; sudo apt -y install pv cgpt tar unzip 在终端中运行命令，制作ChromeOS镜像。把chromeos_filename.bin用从recovery中解压得到的文件名替代，脚本运行完成后回到的名为chromeos.img的系统镜像。\n1 sudo bash chromeos-install.sh -src chromeos_filename.bin -dst chromeos.img 命令运行完成后直接键入ENTER结束。\n将镜像文件写入U盘\n下载Rufus，选中要使用的U盘和镜像文件，将镜像写入U盘。\n进入ChromeOS\n重启电脑，进入BIOS设置界面，关闭secure boot，设置优先从USB启动。\n保存并退出BIOS设置，电脑会自动重启并从U盘启动系统，第一次进入系统时需要等待较长时间。\n安装ChromeOS和Windows双系统 获取文件以及解压同“安装ChromeOS到Windows”中的步骤1、2、3。\n安装ChromeOS双系统同样通过在WSL终端中运行脚本完成，首先新建一个文件夹用于安装系统如/mnt/d/brunch，表示在d盘新建文件夹brunch，然后输入命令。\n1 sudo bash chromeos-install.sh -src chromeos_filename.bin -dst /mnt/d/brunch/chromeos.img -s size 把命令中的chromeos_filename.bin用从recovery中解压得到的文件名替代，size用一个数字替代，定义了分配给ChromeOS磁盘空间，不小于14并且为4的倍数（单位GB）。\n等待脚本执行完成后输入dualboot然后键入ENTER。\n下一步可以安装Grub2Win，实现在开机时选择想要进入的系统。本人未作尝试，具体步骤可以参考brunch的官方安装教程。\n安装Grub2Win后，依次点击Manage Boot Menu-Add A New Entry-Type，选择“Create user section”。此时为自动用记事本新建一个文本文件，在之前设置的/mnt/d/brunch文件夹中打开“chromeos.grub.txt”，将该文件中的内容复制到新建的空文本中。保存Grub2Win的更改，重启电脑，选择ChromeOS进入系统。\n","date":"2023-02-05T11:02:40+08:00","permalink":"https://xland.cyou/p/windows-install-chromeos/","title":"Windows下制作ChromeOS Live USB"},{"content":"基于Python的Telegram Bot，使用pyTelegramBotAPI库。\n准备 创建Bot 点击START私聊@BotFather，输入/newbot开始创建Bot。\n等到BotFather回复后输入想要创建的Bot名称，BotFather再次回复后输入Bot的username，注意username必须以_bot结尾。\n创建完Bot后就可以获取到Bot的token，Telegram Bot API的调用必须提供token。\n安装pyTelegramBotAPI 使用pip安装pyTelegramBotAPI。\n1 pip install pyTelegramBotAPI Bot的运行原理 Bot和一般的用户一样，都有名称和id，可以通过@username查找到Bot。Bot的运行是通过和所有者服务器上的脚本联合实现的，用户通过Telegram向Bot发送信息，Bot的脚本根据Bot的token，就可以在服务器上通过Telegram提供的Bot API获取到用户发送给Bot的信息，从而实现根据用户发送的信息返回给用户相应的回复。\npyTelegramBotAPI是一个Python库，对Telegram Bot API进行了封装。使得开发者不用对API直接调用，使用pyTelegramBotAPI提供的函数和类就可以实现Telegram Bot API的各种功能。\npyTelegramBotAPI的基础使用 新建bot对象 pyTelegramBotAPI中调用API的methods全部定义在TeleBot类中，通过传入Bot token新建bot对象。\n1 2 3 import telebot bot = telebot.TeleBot(\u0026#34;TOKEN\u0026#34;, parse_mode=None) # You can set parse_mode by default. HTML or MARKDOWN TeleBot类中的函数和Telegram Bot API提供的method同名，但是更改了命名规则，例如API中的getMe在TeleBot类对应于get_me，API中的sendMessage被命名为send_message。\nBot提供给用户的回复是通过handler实现的，对于用户发送给Bot的消息，使用message handler进行处理。\n1 2 3 @bot.message_handler(commands=[\u0026#39;start\u0026#39;, \u0026#39;help\u0026#39;]) def send_welcome(message): bot.reply_to(message, \u0026#34;Howdy, how are you doing?\u0026#34;) 上述代码中表示对于用户发送给Bot的消息，定义一个message_handler，这个message_handler在用户发送了指令/start或/help时执行send_welcome函数，产生对用户的回复”Howdy, how are you doing?“。\nmessage对象 用户对Bot发送消息后，通过Telegram Bot API获得到的是一个名为message的JSON对象，包含了消息内容，用户id等相关信息，详情可参考Telegram官方文档。\n在上述给出的message_handler示例代码中，send_welcome函数传入参数message对象，reply_to通过message中包含的属性chat.id等获取用户id，从而向用户发送回复信息。\n需要注意的是，由于from是Python中的保留字，在pyTelegramBotAPI中，message的属性名from被替换为from_user。\nmessage handler message handler用来对用户发送的message类消息做出反应（用户发送的消息一般都为message，除此之外还有投票poll、频道推文channel post等其他类型），用于处理其他类消息的handler还有poll handler、channel post handler等。\n1 2 3 @bot.message_handler(filters) def function_name(message): bot.reply_to(message, \u0026#34;This is a message handler\u0026#34;) 在message handler的一般形式中，filters用来对message进行筛选，使该message_handler只对特定类型的message进行响应。filters的一般格式为name=argument，name表示筛选类型，argument代表筛选范围。例如commands=['start', 'help']表示只对命令/start和/help做出反应。\n官方给出的filters支持的类型如下：\nname argument Condition content_types list of strings (default [\u0026rsquo;text\u0026rsquo;]) True if message.content_type is in the list of strings. regexp a regular expression as a string True if re.search(regexp_arg) returns True and message.content_type == \u0026rsquo;text\u0026rsquo; (See https://docs.python.org/2/library/re.html) commands list of strings True if message.content_type == \u0026rsquo;text\u0026rsquo; and message.text starts with a command that is in the list of strings. chat_types list of chat types True if message.chat.type in your filter func a function (lambda or function reference) True if the lambda or function reference returns True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import telebot bot = telebot.TeleBot(\u0026#34;TOKEN\u0026#34;) # 只处理命令 \u0026#39;/start\u0026#39; 和 \u0026#39;/help\u0026#39; @bot.message_handler(commands=[\u0026#39;start\u0026#39;, \u0026#39;help\u0026#39;]) def handle_start_help(message): pass # 只处理用户发送内容为“文件”和“音频”的message @bot.message_handler(content_types=[\u0026#39;document\u0026#39;, \u0026#39;audio\u0026#39;]) def handle_docs_audio(message): pass # Handles all text messages that match the regular expression @bot.message_handler(regexp=\u0026#34;SOME_REGEXP\u0026#34;) def handle_message(message): pass # Handles all messages for which the lambda returns True @bot.message_handler(func=lambda message: message.document.mime_type == \u0026#39;text/plain\u0026#39;, content_types=[\u0026#39;document\u0026#39;]) def handle_text_doc(message): pass # Which could also be defined as: def test_message(message): return message.document.mime_type == \u0026#39;text/plain\u0026#39; @bot.message_handler(func=test_message, content_types=[\u0026#39;document\u0026#39;]) def handle_text_doc(message): pass # Handlers can be stacked to create a function which will be called if either message_handler is eligible # This handler will be called if the message starts with \u0026#39;/hello\u0026#39; OR is some emoji @bot.message_handler(commands=[\u0026#39;hello\u0026#39;]) @bot.message_handler(func=lambda msg: msg.text.encode(\u0026#34;utf-8\u0026#34;) == SOME_FANCY_EMOJI) def send_something(message): pass ","date":"2023-01-10T19:39:43+08:00","permalink":"https://xland.cyou/p/telegram-bot/","title":"Telegram Bot（一）Python库pyTelegramBotAPI的使用"},{"content":"神经网络 neural network 神经网络由多个神经元互相连接组成，每个神经元是一个计算单元，位于同一层级的多个神经元组成一个网络层。一般的神经网络一般由三种网络层组成：输入层，隐藏层和输出层。\n神经网络的组成 激活函数 Activatioin Functioin\n神经元的输入经过激活函数得到输出，激活函数的输出值定义了神经元是否被激活。激活函数有几种不同的形式，它的选取取决于期望的神经元输出。\nBinary 输入为正数时神经元输出1，输入为负数时神经元输出0\n$$ f(x)= \\small\\begin{cases} 0, \u0026amp; \\text{if } x \u0026lt; 0 \\newline 1, \u0026amp; \\text{if } x\\geq 0 \\end{cases} $$\nSigmod 由输入值得到0和1之间的连续输出值\n$$ f(x) = {\\large \\frac{1}{1+e^{-x}}} $$\nTanh 由输入值得到-1和1之间的连续输出值\n$$ f(x) = {\\large \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}} $$\nReLU 当输入为负数时输出为0，输入为正数时保持输入值\n$$ f(x)= \\small \\begin{cases} 0, \u0026amp; \\text{if } x \u0026lt; 0\\newline x, \u0026amp; \\text{if } x\\geq 0 \\end{cases} $$\n权重 Weights\n由前一神经元输出到下一神经元输入的加权\n偏置 Bias\n$$ output=activation function(\\sum{(weights * inputs) + bias}) $$\n在PyTorch中建立神经网络 torch.nn提供了建立神经网络需要的组件，在PyTorch中神经网络是一个module，一个神经网络由多个同样是module的网络层组成。所有的神经网络模型都是nn.Module的子类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import os import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms device = \u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39; print(\u0026#39;Using {} device\u0026#39;.format(device)) class NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10), nn.ReLU() ) def forward(self, x): x = self.flatten(x) logits = self.linear_relu_stack(x) return logits model = NeuralNetwork().to(device) 通过向模型传递输入数据，模型会自动调用forward()，并返回模型输出。\n1 2 3 4 5 X = torch.rand(1, 28, 28, device=device) # 生成模型输入数据 logits = model(X) # 向模型传递输入数据，model.forward()自动执行，得到输出logits pred_probab = nn.Softmax(dim=1)(logits) y_pred = pred_probab.argmax(1) print(f\u0026#34;Predicted class: {y_pred}\u0026#34;) nn.Linear nn.Linear随机初始化每层的权重和偏置，并储存在tensors中\nnn.Flatten nn.Flatten将28x28的图片转换为一个784维的输入向量\nnn.Sequential nn.Sequential是一个module的容器，数据经过nn.Sequential后，会按照定义时的顺序，依次进行运算。\n1 2 3 4 5 6 7 8 9 10 self.linear_relu_stack = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU() ) logits = self.linear_relu_stack(x) # x输入linear_relu_stack后，依次经过module nn.Linear(28*28, 512)， # nn.ReLU()，nn.Linear(512, 512)，nn.ReLU() nn.ReLU 激活函数ReLU\n模型参数 神经网络的参数包括每一个网络层的weight和bais，通过模型的parameters()或named_parameters()可以获取模型中的所有参数\n1 2 3 4 print(\u0026#34;Model structure: \u0026#34;, model, \u0026#34;\\n\\n\u0026#34;) for name, param in model.named_parameters(): print(f\u0026#34;Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\u0026#34;) ","date":"2023-01-09T15:14:55+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-model/","title":"PyTorch基础 （三）网络模型"},{"content":"PyTorch provides two data primitives: torch.utils.data.DataLoaderand torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Datasetstores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\nloading a dataset load the Fashion-MNIST dataset from TorchVision. The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 %matplotlib inline import torch from torch.utils.data import Dataset from torchvision import datasets from torchvision.transforms import ToTensor, Lambda import matplotlib.pyplot as plt training_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, # data storage path train=True, # load training data download=True, # download data from internet to root if data don\u0026#39;t found at root transform=ToTensor() # data to tensor ) test_data = datasets.FashionMNIST( root=\u0026#34;data\u0026#34;, train=False, # load test data download=True, transform=ToTensor() ) Iterating and Visualizing the Dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 labels_map = { 0: \u0026#34;T-Shirt\u0026#34;, 1: \u0026#34;Trouser\u0026#34;, 2: \u0026#34;Pullover\u0026#34;, 3: \u0026#34;Dress\u0026#34;, 4: \u0026#34;Coat\u0026#34;, 5: \u0026#34;Sandal\u0026#34;, 6: \u0026#34;Shirt\u0026#34;, 7: \u0026#34;Sneaker\u0026#34;, 8: \u0026#34;Bag\u0026#34;, 9: \u0026#34;Ankle Boot\u0026#34;, } figure = plt.figure(figsize=(8, 8)) cols, rows = 3, 3 for i in range(1, cols * rows + 1): sample_idx = torch.randint(len(training_data), size=(1,)).item() img, label = training_data[sample_idx] figure.add_subplot(rows, cols, i) plt.title(labels_map[label]) plt.axis(\u0026#34;off\u0026#34;) plt.imshow(img.squeeze(), cmap=\u0026#34;gray\u0026#34;) plt.show() Training with DataLoaders While training a model, we use DataLoader to pass samples in \u0026ldquo;minibatches\u0026rdquo;, reshuffle the data at every epoch to reduce model overfitting, and use Python\u0026rsquo;s multiprocessing to speed up data retrieval. To use DataLoader, we need to set the followings paraments:\ndataset-dataset from which to load the data batch_size-how many samples per batch to load shuffle-set to True to have the data reshuffled at every epoch (default: False) 1 2 3 4 from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) We have loaded that dataset into the Dataloader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels(containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled (for finer-grained control over the data loading order.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Display image and label. train_features, train_labels = next(iter(train_dataloader)) # 得到batch_size=64的训练数据 print(f\u0026#34;Feature batch shape: {train_features.size()}\u0026#34;) # output: Feature batch shape: torch.Size([64, 1, 28, 28]) # batch_size为64，训练数据的每一项是一个28x28的图片 print(f\u0026#34;Labels batch shape: {train_labels.size()}\u0026#34;) # 绘制训练数据batch中第一个图像 img = train_features[0].squeeze() label = train_labels[0] plt.imshow(img, cmap=\u0026#34;gray\u0026#34;) plt.show() print(f\u0026#34;Label: {label}\u0026#34;) iter(object[, sentinel]) 用于生成迭代器，传入参数object必须为支持迭代的对象，next() 返回迭代器下一项。\nNormalizatioin Normalization is a common data pre-processing technique that is applied to scale or transform the data to make sure there\u0026rsquo;s an equal learning contribution from each feature.\nTransforms We use transforms to perform some manipulation of the data and make it suitable for training. transform to modify the features and target_transform to modify the labels. ToTensor converts a PIL image or NumPy ndarray into a FloatTensor and scales the image\u0026rsquo;s pixel intensity values in the range [0., 1.]\n","date":"2023-01-07T11:13:45+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-dataset/","title":"PyTorch基础 （二）Dataset和DataLoader"},{"content":"张量（tensor）是一种类似于数组和矩阵的特殊数据结构。tensor类似于NumPy中的ndarray，两者也可以使用相同的内存地址。\n创建Tensor 直接使用数据创建 1 2 3 4 5 import torch import numpy as np data = [[1, 2],[3, 4]] x_data = torch.tensor(data) 使用NumPy array创建 1 2 3 4 5 6 7 8 9 10 np_array = np.array(data) x_np = torch.from_numpy(np_array) print(f\u0026#34;Numpy np_array value: \\n {np_array} \\n\u0026#34;) print(f\u0026#34;Tensor x_np value: \\n {x_np} \\n\u0026#34;) np.multiply(np_array, 2, out=np_array) print(f\u0026#34;Numpy np_array after * 2 operation: \\n {np_array} \\n\u0026#34;) # x_np会和np_array一起改变 print(f\u0026#34;Tensor x_np value after modifying numpy array: \\n {x_np} \\n\u0026#34;) 由于np_array和x_np使用相同的内存地址，两者的值会同时改变\n使用其他tensor创建 tensor可以使用其他tensor的属性（包括tensor的shape，dtype）进行初始化\n1 2 3 4 5 6 7 x_ones = torch.ones_like(x_data) # x_ones会保持和x_data相同的属性，所有元素都为1 print(f\u0026#34;Ones Tensor: \\n {x_ones} \\n\u0026#34;) x_rand = torch.rand_like(x_data, dtype=torch.float) # x_rand保持x_data的属性，dtype设为torch.float print(f\u0026#34;Random Tensor: \\n {x_rand} \\n\u0026#34;) 使用随机数或常数创建 1 2 3 4 5 6 7 8 shape = (2,3,) rand_tensor = torch.rand(shape) ones_tensor = torch.ones(shape) zeros_tensor = torch.zeros(shape) print(f\u0026#34;Random Tensor: \\n {rand_tensor} \\n\u0026#34;) print(f\u0026#34;Ones Tensor: \\n {ones_tensor} \\n\u0026#34;) print(f\u0026#34;Zeros Tensor: \\n {zeros_tensor}\u0026#34;) Tensor的属性 1 2 3 4 5 tensor = torch.rand(3,4) print(f\u0026#34;Shape of tensor: {tensor.shape}\u0026#34;) print(f\u0026#34;Datatype of tensor: {tensor.dtype}\u0026#34;) print(f\u0026#34;Device tensor is stored on: {tensor.device}\u0026#34;) tensor的属性包括维度shape，数据类型dtype，和存储的设备类型device\nTensor的操作 tensor的参考文档 tensor创建时默认处于CPU中，如果要使用GPU进行tensor计算需要使用.to设置\n1 2 3 # 当GPU可用时，将tensor转移到GPU中 if torch.cuda.is_available(): tensor = tensor.to(\u0026#39;cuda\u0026#39;) Tensor索引 1 2 3 4 5 6 tensor = torch.ones(4, 4) print(\u0026#39;First row: \u0026#39;,tensor[0]) print(\u0026#39;First column: \u0026#39;, tensor[:, 0]) # 第一列 print(\u0026#39;Last column:\u0026#39;, tensor[..., -1]) # 最后一列 tensor[:,1] = 0 # 第二列元素置为0 print(tensor) Tensor合并 tensor的合并有两种方法torch.cat和torch.stack\n1 2 t1 = torch.cat([tensor, tensor, tensor], dim=1) t1 = torch.stack([tensor, tensor, tensor], dim=1) Tensor的数学运算 1 2 3 4 5 6 7 8 9 10 11 12 13 # 矩阵乘法 y1 = tensor @ tensor.T y2 = tensor.matmul(tensor.T) y3 = torch.rand_like(tensor) torch.matmul(tensor, tensor.T, out=y3) # 矩阵对应元素相乘 z1 = tensor * tensor z2 = tensor.mul(tensor) z3 = torch.rand_like(tensor) torch.mul(tensor, tensor, out=z3) 单元素的tensor 单元素的tensor可以使用item()转变为Python中的数值量\n1 2 3 agg = tensor.sum() # 将tensor中的元素相加 agg_item = agg.item() # 将单元素agg转为Python数值 print(agg_item, type(agg_item)) 自动赋值运算 自动赋值运算通常在方法后有 _ 作为后缀，在运算中会直接改变运算量\n1 2 3 print(tensor, \u0026#34;\\n\u0026#34;) tensor.add_(5) # add_改变了tensor的元素值，每个元素加上5 print(tensor) Tensor和NumPy Tensor转为NumPy array 1 2 3 4 t = torch.ones(5) print(f\u0026#34;t: {t}\u0026#34;) n = t.numpy() print(f\u0026#34;n: {n}\u0026#34;) tensor和NumPy array共享内存，两者会同时改变\nNumPy array转为Tensor 1 2 n = np.ones(5) t = torch.from_numpy(n) ","date":"2023-01-06T17:12:03+08:00","image":"https://xland.cyou/p/pytorch-tensor/pytorch.webp","permalink":"https://xland.cyou/p/pytorch-tensor/","title":"PyTorch基础 （一）Tensors"},{"content":"之前没有通过引导卸载VMware Workstation，直接把整个文件夹删了，导致卸载不彻底。VMware在安装时会先检测是否已经安装，使得我的电脑无法再次安装VMware Workstation。后来按照官方的卸载教程试了几次都没成功，偶然发现系统环境变量中还有VMware的路径，才解决了这个问题。关键在于卸载后没有删除环境变量，所以被认为没有完全卸载VMware Workstation。\n通过Workstation安装程序自动清理 下载对应版本的安装程序，在当前文件夹打开终端，在终端中输入\n1 VMware-workstation-full-xxx-xxx.exe /clean 停止VMware相关的服务 在Windows搜索框搜索services.msc，打开“服务”，停止所有VMware相关的服务。\nVMware Authorization Service VMware Authentication Service VMware Registration Service VMware DHCP Service VMware NAT Service VMware USB Arbitration Service VMware Workstation Server VMware WSX Service 删除VMware network bridge adapter 打开控制面板\\网络和 Internet\\网络连接 右键，属性，选择VMware Bridge Protocol，卸载 删除VMware相关的网络适配器 打开控制面板\\硬件和声音\\设备管理器 在“查看”工具栏勾选上“显示隐藏的设备” 点击“网络适配器”，卸载名字包含VMware的适配器 删除和VMware有关的文件夹 程序安装目录 数据目录\n默认路径C:\\Program Files(X86)\\VMware\\ 开始菜单中的VMware\n路径C:\\ProgramData\\VMware 快捷方式 其他文件 C:\\Windows\\system32\\vmnat.exe C:\\Windows\\system32\\vmnetbridge.exe C:\\Windows\\system32\\VMNetDHCP.exe C:\\Windows\\system32\\vmnetdhcp.leases C:\\Windows\\system32\\vmxw2ksetup.dll C:\\Windows\\system32\\vnetprobe.exe C:\\Windows\\system32\\vnetprobelib.dll C:\\Windows\\system32\\vnetinst.dll C:\\Windows\\system32\\vnetlib.dll C:\\Windows\\system32\\vnetlib.exe C:\\Windows\\system32\\drivers\\vmnet.sys C:\\Windows\\system32\\drivers\\vmnetx.sys C:\\Windows\\system32\\drivers\\VMparport.sys C:\\Windows\\system32\\drivers\\vmx86.sys C:\\Windows\\system32\\drivers\\vmnetadapter.sys C:\\Windows\\system32\\drivers\\vmnetbridge.sys C:\\Windows\\system32\\drivers\\vmnetuserif.sys C:\\Windows\\system32\\drivers\\hcmon.sys C:\\Windows\\system32\\drivers\\vmusb.sys 注册表\n打开注册表管理器，删除以下注册表 HKEY_CLASSES_ROOT\\Installer\\Features\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\Products\\A57F49D06AE015943BFA1B54AFE9506C HKEY_CLASSES_ROOT\\Installer\\UpgradeCodes\\3F935F414A4C79542AD9C8D157A3CC39 HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\{0D94F75A-0EA6-4951-B3AF-B145FA9E05C6} HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Wow6432Node\\VMware, Inc.\\Installer\\VMware Workstation HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\Applications\\vmware.exe 删除环境变量 打开系统环境变量设置，删除VMware Workstation的执行路径\n重启电脑，就完成了VMware Workstation的完全卸载。\n各版本路径存在一些不同，具体参考官方文档。\n","date":"2022-03-19T12:05:03+08:00","permalink":"https://xland.cyou/p/uninstall-vmware/","title":"完全卸载VMware Workstation"},{"content":"关于Hugo Hugo的便利之处在于，用户只需编辑markdown文档，Hugo会自动将markdown文档转换为网页。Hugo根据存放于content文件夹中的用户markdown文件，生成网页源文件，并存放于public文件夹中。\n将博客部署到GitHub Pages，只需将Hugo生成的public文件夹推送到GitHub仓库。\n关于Github Pages 官方文档定义：\nGitHub Pages is a static site hosting service that takes HTML, CSS, and JavaScript files straight from a repository on GitHub, optionally runs the files through a build process, and publishes a website.\nGithub Pages 有两种形式，个人/组织页面和项目页面，两者访问时的url不同，为了能够使用https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/访问个人博客，应当设置成个人页面。\nUser/Organization Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/) Project Pages (https://\u0026lt;USERNAME|ORGANIZATION\u0026gt;.github.io/\u0026lt;PROJECT\u0026gt;/) 创建User Page 在Github新建仓库时，个人页面的创建和项目页面不同：\n用于个人页面的仓库必须被用户（而不是组织）所有，并将仓库命名为\u0026lt;username\u0026gt;.github.io\n个人页面的源文件放置于仓库的默认分支中，项目页面需存放在特定分支\n创建仓库时需要注意，免费用户创建的页面仓库必须设置为Public\n选择 Initialize this repository with a README ，完成仓库创建\n将源文件推送到仓库 在创建的仓库中复制远程仓库地址\n在Hugo生成的文件夹中，在终端中输入\n1 2 3 4 5 6 7 hugo #生成网页源文件 cd public #生成的源文件存放在public文件夹中，只需将该文件夹推送到所创建的仓库中 git init #git初始化 git remote add origin git@github.com:\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git #关联远程仓库 git add . git commit -m \u0026#34;first commit\u0026#34; #在本地提交更改 git push -u origin master #将更改推送到远程仓库 此时GitHub仓库中拥有main和master两个分支，其中main分支是创建仓库是自动生成的默认分支，mater分支由本地推送，即博客的网页源文件\nGitHub Pages的个人页面默认从main分支提取网页源文件，所以还需要在仓库的settings-pages-source中将分支改为master分支\n之后即可通过\u0026lt;username\u0026gt;.github.io访问博客页面\n","date":"2022-02-12T19:34:01+08:00","permalink":"https://xland.cyou/p/hugo_blog/","title":"将Hugo博客部署到Github Pages"}]